[{"path":"/articles/00-introduction.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Introduction to the package","text":"Note windows users: installation github requires RTools.","code":"# install.packages(\"devtools\") devtools::install_github(\"hydrosolutions/riversCentralAsia\",                           quiet = TRUE) library(riversCentralAsia, quietly = TRUE)"},{"path":"/articles/00-introduction.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Introduction to the package","text":"package includes example data set discharge time series well temperature precipitation time series runoff formation zone Chirchiq river basin.","code":"library(riversCentralAsia, quietly = TRUE) library(tidyverse, quietly = TRUE) library(timetk, quietly = TRUE) ChirchikRiverBasin  # load data #> # A tibble: 29,892 × 14 #>    date        data  norm units type  code  station  river basin resol…¹ lon_U…² #>    <date>     <dbl> <dbl> <chr> <fct> <chr> <chr>    <chr> <chr> <fct>     <dbl> #>  1 1932-01-10  48.8  38.8 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  2 1932-01-20  48.4  37.5 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  3 1932-01-31  42.4  36.6 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  4 1932-02-10  43.7  36.4 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  5 1932-02-20  44.2  36.3 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  6 1932-02-29  47.7  36.9 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  7 1932-03-10  54.1  39.4 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  8 1932-03-20  63.2  47.6 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #>  9 1932-03-31 103    60.5 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #> 10 1932-04-10 103    86.4 m3s   Q     16279 Khudayd… Chat… Chir… dec      598278 #> # … with 29,882 more rows, 3 more variables: lat_UTM42 <dbl>, #> #   altitude_masl <dbl>, basinSize_sqkm <dbl>, and abbreviated variable names #> #   ¹​resolution, ²​lon_UTM42 ChirchikRiverBasin |>    filter(type == \"Q\",           code %in% c(\"16279\", \"16290\", \"16298\", \"16300\")) |>    group_by(code, station, river) |>    drop_na() |>    plot_time_series(     date, data,     .interactive = TRUE,     .facet_ncol  = 2,      .facet_collapse = TRUE, .facet_collapse_sep = \" - \",      .smooth      = FALSE,      .y_lab = \"Q [m3/s]\")"},{"path":"/articles/00-introduction.html","id":"tools","dir":"Articles","previous_headings":"","what":"Tools","title":"Introduction to the package","text":"package riversCentralAsia includes variety functions facilitate data pre- post-processing hydrological hydraulic modelling RS Minerve Central Asia. RS Minerve free hydrological hydraulic modelling software developed Switzerland CREALP partners. summary, functions can grouped : * Reading writing input output files RS Minerve * Pre- post-processing data hydrolgical modelling RS Minerve * Glacier modelling tools * Various helper tools analysing plotting hydrological data","code":""},{"path":"/articles/00-introduction.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Introduction to the package","text":"packages builds previous work R, RStudio RS Minerve developers. relies free data made available publicly funded research. Open source R methods books public forums inspired supported writing package.","code":""},{"path":"/articles/01-description_raw_data.html","id":"time-series","dir":"Articles","previous_headings":"","what":"Time series","title":"Description of data raw types","text":"former Soviet republics, river discharge also climate variables like temperature precipitation often available hydrological yearbooks published national HydroMeteorological institutes. common data format time series years rows months decade (10-day interval) per year columns indicated two examples . Example monthly data format. Example decadal data format. load time series data using function loadTabularData, save cells without headers csv file. recommend commas field separators points decimal separators. valid csv file example monthly time series data given . 1990,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2 1991,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2 1992,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2","code":""},{"path":"/articles/01-description_raw_data.html","id":"example","dir":"Articles","previous_headings":"Time series","what":"Example","title":"Description of data raw types","text":"article discharge processing example show can load csv file produce various visualizations using riversCentralAsia package (’s numerous dependencies).","code":""},{"path":"/articles/01-description_raw_data.html","id":"climate-raster-data","dir":"Articles","previous_headings":"","what":"Climate raster data","title":"Description of data raw types","text":"Due limited amount monitoring locations Central Asia, use re-analysis climate data ’s distinct advantages. course, station data still highly relevant validate re-analysis data , necessary, correcting potential biases re-analysis data. chapter Climate data hydrological modelling course book detailed description use re-analysis data hydrological modelling Central Asia. refrain technical description data formats can processed riversCentralAsia package.","code":""},{"path":"/articles/01-description_raw_data.html","id":"chelsa","dir":"Articles","previous_headings":"Climate raster data","what":"CHELSA","title":"Description of data raw types","text":"CHELSA v2.1 data Karger et al. (2021) provided us D. Karger annual .nc (NetCDF) files daily temperature precipitation Central Asian region. can access CHELSA data via website https://chelsa-climate.org/. NetCDF files can quite large often convenient use different software R inspect /crop area interest. quick inspection NetCDF files recommend free GUI Panoply (Panoply development team 2022). Cropping NetCDF can conveniently done using command line tool CDO (Manager: Luis Kornblueh, Ralf Mueller, Uwe Schu Developer: Dian Putrasahan, Fabian Wachsmann, Irina Fast, Joerg Behrens, Karin Meier-Fleischer, Karl-Hermann Wieners, Mathis Rosenhauer, Oliver Heidmann, Ralf Quast, Reinhard Budich, Thomas Jahns 2022). CDO works Unix-type systems like Ubuntu Linux distributions MacOS. Fortunately, can also activate Ubuntu Windows OS (10 newer). CDO FAQ lead quickly commands inspect NetCDF file crop region interest. CHELSA v2.1 NetCDF files WGS84 projection EPSG:4326. Please refer documentation data set download. includes daily precipitation sums mm (varname = pr) daily average near surface temperature deg C (varname = tas) day year. one nc file year climate variable. date included names daily images format X%Y.%m.%d (see example ).","code":""},{"path":"/articles/01-description_raw_data.html","id":"example-1","dir":"Articles","previous_headings":"Climate raster data > CHELSA","what":"Example","title":"Description of data raw types","text":"reproduce examples , please download file test_gen_HRU_Climate_CSV_RSMinerve_input_file.nc test folder riversCentralAsia package github. file contains one raster image daily mean temperatures (please read technical documentation CHELSA v2.1 data using ). can plot temperature raster January 1, 1979: Example temperature raster January 1, 1979. Data: CHELSA v2.1 (1 km grid resolution).","code":"library(raster) library(riversCentralAsia)  # Download the example nc file from https://github.com/hydrosolutions/riversCentralAsia/blob/master/tests/testthat/test_gen_HRU_Climate_CSV_RSMinerve_input_file.nc  # Adapt the path to the nc file on your computer ncfilepath = \"tests/testthat/test_gen_HRU_Climate_CSV_RSMinerve_input_file.nc\"  # Read in the nc file as raster brick chelsa_temperature_data <- raster::brick(ncfilepath)  # Inspect the brick:  chelsa_temperature_data #> class      : RasterBrick  #> dimensions : 18, 21, 378, 365  (nrow, ncol, ncell, nlayers) #> resolution : 0.008333333, 0.008333333  (x, y) #> extent     : 70.01653, 70.19153, 41.70819, 41.85819  (xmin, xmax, ymin, ymax) #> crs        : +proj=longlat +datum=WGS84 +no_defs  #> source     : test_gen_HRU_Climate_CSV_RSMinerve_input_file.nc  #> names      : X1979.01.01, X1979.01.02, X1979.01.03, X1979.01.04, X1979.01.05, X1979.01.06, #> X1979.01.07, X1979.01.08, X1979.01.09, X1979.01.10, X1979.01.11, X1979.01.12, X1979.01.13, #> X1979.01.14, X1979.01.15, ...  #> Date       : 1979-01-01, 1979-12-31 (min, max) #> varname    : tas plot(chelsa_temperature_data$X1979.01.01,       xlab = \"Longitute\", ylab = \"Latitude\", main = \"Date: January 1, 1979\",      legend.args = list(text = \"Temperature [deg C]\", side=4, line=2.5))"},{"path":"/articles/01-description_raw_data.html","id":"climate-projections","dir":"Articles","previous_headings":"Climate raster data","what":"Climate projections","title":"Description of data raw types","text":"use climate projection data hydrological modelling described detail respective chapter online course book. mentioned course book, pre-processing climate projection data beginners level task requires working knowledge cdo (similar NetCDF processing tool) outputs climate models consistent (e.g. treatment leap years, date handling formats, units, projections, etc.). data package course book includes future projections climate variables compatible model selection used impact assessments carried phase 3a Inter-Sectoral Impact Model Intercomparison Project (ISIMIP3b) (ISIMIP3 consortium 2022). package riversCentralAsia can process harmonized climate projection data, .e. raw climate projections edited consistent dates, units projections. format nc files almost CHELSA v2.1 nc files described . difference layers names include minutes seconds climate projection files. , however, make difference riversCentralAsia package. wish download projections climate models, can download climate projection data CMIP 6 phase Copernicus data repository app. recommended inspect downloaded data obvious problems using panoply reformat data riversCentralAsia-package-readable format using cdo R (scripting language choosing).","code":""},{"path":"/articles/01-description_raw_data.html","id":"example-2","dir":"Articles","previous_headings":"Climate raster data > Climate projections","what":"Example","title":"Description of data raw types","text":"reproduce example , please download example nc file data repository course book. contains daily temperatures general circulation model (GCM) GFDL-ESM4 shared socio-economic scenario (SSP) 1 -2.6 January 2012 end century. Please refer course book detailed explanation GCMs SSPs. file contains one raster image daily mean temperatures (please refer course book chapter climate data details use data hydrological modelling). can plot temperature raster January 1, 2012: Example temperature raster January 1, 2012. Data: GCM GFD-ESM4, SSP126 (approximately 1-1.5 km grid resolution).","code":"# Download the example nc file from https://www.dropbox.com/s/aw3mwh0ysydgu9j/tas_day_GFDL-ESM4_ssp126_r1i1p1f1_gr1.nc?dl=0  # Adapt the path to the nc file on your computer ncfilepath = \"C:../../../caham_data/central_asia_domain/climate/fut_sim/tas_day_GFDL-ESM4_ssp126_r1i1p1f1_gr1.nc\"  # Read in the nc file as raster brick GFDESM4_SSP126_temperature_data <- raster::brick(ncfilepath)  # Inspect the brick:  GFDESM4_SSP126_temperature_data #> class      : RasterBrick  #> dimensions : 20, 24, 480, 32506  (nrow, ncol, ncell, nlayers) #> resolution : 1.25, 1  (x, y) #> extent     : 55, 85, 30, 50  (xmin, xmax, ymin, ymax) #> crs        : +proj=longlat +datum=WGS84 +no_defs  #> source     : tas_day_GFDL-ESM4_ssp126_r1i1p1f1_gr1.nc  #> names      : X2012.01.01.12.00.00, X2012.01.02.12.00.00, X2012.01.03.12.00.00, X2012.01.04.12.00.00, X2012.01.05.12.00.00, X2012.01.06.12.00.00, X2012.01.07.12.00.00, X2012.01.08.12.00.00, X2012.01.09.12.00.00, X2012.01.10.12.00.00, X2012.01.11.12.00.00, X2012.01.12.12.00.00, X2012.01.13.12.00.00, X2012.01.14.12.00.00, X2012.01.15.12.00.00, ...  #> Date/time  : 2012-01-01 12:00:00, 2100-12-30 12:00:00 (min, max) #> varname    : tas plot(GFDESM4_SSP126_temperature_data$X2012.01.01.12.00.00,       xlab = \"Longitute\", ylab = \"Latitude\", main = \"Date: January 1, 2012\",      legend.args = list(text = \"Temperature [deg C]\", side=4, line=2.5))"},{"path":[]},{"path":[]},{"path":"/articles/03-RSMinerveIO.html","id":"reading-and-writing-parameters","dir":"Articles","previous_headings":"","what":"Reading and writing parameters","title":"I/O for RS Minerve","text":"following RSMinerve objects currently supported riversCentralAsia package: - Station - Source - SOCONT - Kinematic - Junction - GSM - HBV92 - Comparator parameters objects described RS MINERVE User Manual.","code":""},{"path":"/articles/03-RSMinerveIO.html","id":"example","dir":"Articles","previous_headings":"Reading and writing parameters","what":"Example","title":"I/O for RS Minerve","text":"reproduce example , please download file Atbashy_PAR_postCal.txt demo data folder available dropbox. want test wider number RS MINERVE /O functions, recommend downloading entire example data folder . following shows example model parameters can changed written RS MINERVE-readable format.","code":"library(tidyverse) library(lubridate) library(riversCentralAsia)  # Download the file Atbashy_PAR_postCal.txt from https://www.dropbox.com/s/y4r44h06jwdnsde/Atbaschy_PAR_postCal.txt?dl=0  # Adapt the path below  parameters_orig <- readRSMParameters(\"../../atbashy_glacier_demo_data/RSMINERVE/Atbaschy_PAR_postCal.txt\") |>    dplyr::filter(Parameters == \"Ku [1/d]\")   ggplot(parameters_orig) +    geom_col(aes(Zone, Values), position = \"dodge\") +    ylab(parameters_orig$Parameters[1]) +    theme_bw() # Doubble all Ku-values in zone A:  parameters <- readRSMParameters(   \"../../atbashy_glacier_demo_data/RSMINERVE/Atbaschy_PAR_postCal.txt\") |>    mutate(Values = ifelse(Parameters == \"Ku [1/d]\" & Zone == \"A\", Values * 2,                           Values))  comparison <- parameters_orig |>    mutate(Set = \"Original\") |>    add_row(parameters |> dplyr::filter(Parameters == \"Ku [1/d]\") |>              mutate(Set = \"Modified\"))  ggplot(comparison) +    geom_col(aes(Zone, Values, fill = Set), position = \"dodge\") +    scale_fill_viridis_d() +    ylab(parameters_orig$Parameters[1]) +    theme_bw()  # Uncomment to write and adapt the output file path (second argument). # writeRSMParameters(parameters, \"Parameters_modified_Ku.txt\")"},{"path":"/articles/03-RSMinerveIO.html","id":"reading-simulation-results","dir":"Articles","previous_headings":"","what":"Reading simulation results","title":"I/O for RS Minerve","text":"Another useful application RS MINERVE /O functions reading simulation results analysis partitioning total basin discharge individual fluxes. code illustrates may done:","code":""},{"path":"/articles/03-RSMinerveIO.html","id":"writing-a-check-node-file","dir":"Articles","previous_headings":"Reading simulation results","what":"Writing a check node file","title":"I/O for RS Minerve","text":"Writing selection node file can imported RS MINERVE selection can used export selected simulation results. useful large models many model objects cumbersome manually toggle desired results RS MINERVE. check node file written xml format (see RS MINERVE documentation). can look example check node file demo data folder. need write specific check node file, typically ask RS MINERVE write example file (selecting examples variables want export) write check node file R adapting example . read simulation results.","code":"# In this example, we want to export all fluxes and some states from all  # hydrological response units (HRU) in our hydrological model from RS MINERVE.  # # Make sure you have the example shape file with the hydrological response units  # used for hydrological modelling in RS MINERVE (16076_HRU.shp) downloaded from  # the example data set  # https://www.dropbox.com/s/ob5xrbp2ynfxzn3/16076_HRU.shp?dl=0  # Adapt the path below # This reads in the names of the HRUs  Object_IDs <- sf::st_read(\"../../atbashy_glacier_demo_data/GIS/16076_HRU.shp\") |>    sf::st_drop_geometry()     # Write check node file hbv_var_list <- c(\"Qr (m3/s)\", \"Qu (m3/s)\", \"Ql (m3/s)\", \"SWE (m)\", \"HUM (m)\",                    \"SU (m)\", \"SL (m)\", \"Peq (m/s)\") station_var_list <- c(\"P (m/s)\")  data <- tibble(   Model = rep(\"Model Atbaschy\",                length(Object_IDs$name)*length(hbv_var_list) +                  length(Object_IDs$name)*length(station_var_list)),    Object = c(rep(\"HBV92\", (length(Object_IDs$name)*length(hbv_var_list))),              rep(\"Station\", (length(Object_IDs$name)*length(station_var_list)))),    ID = c(rep(Object_IDs$name, each = length(hbv_var_list)),           paste(\"Station\", rep(Object_IDs$name, each = length(station_var_list)),                 sep = \" \")),    Variable = c(rep(hbv_var_list, length(Object_IDs$name)),                 rep(station_var_list, length(Object_IDs$name))) )  writeSelectionCHK(filepath = paste0(data_path,                                      \"RSMINERVE/FluxesAndStates.chk\"),                    data = data,                    name = \"Fluxes and states\")"},{"path":"/articles/03-RSMinerveIO.html","id":"reading-plotting-results","dir":"Articles","previous_headings":"Reading simulation results","what":"Reading & plotting results","title":"I/O for RS Minerve","text":"reproduce example , please download example files demo data folder available dropbox adapt paths .","code":"# Download the demo data folder from https://www.dropbox.com/sh/r0lqggc77ka0uxd/AAChuIyLHHFIfAdgxNKiU2dpa?dl=0  # Adapt the path to the demo data folder on your computer data_path <- \"../../atbashy_glacier_demo_data/\"  # Fluxes and model states per elevation bands fs <- readResultCSV(paste0(data_path,                            \"RSMINERVE/Atbaschy_Results_Fluxes_and_States.csv\")) |>    mutate(model = gsub(\"Station \", \"\", model))  Tth <- 1  # HBV model parameter for partitioning of solid and liquid precipitation forcing <- readForcingCSV(paste0(data_path,                                   \"RSMINERVE/hist_obs_rsm.csv\")) |>    dplyr::select(-c(X, Y, Z, Category)) |>    pivot_wider(names_from = c(Sensor, Unit), names_sep = \"_\", values_from = Value) |>    mutate(Month = month(Date),           P_mmd = `P_mm/d`,           Rain_mmd = ifelse(T_C >=  Tth, `P_mm/d`, 0),           Snow_mmd = ifelse(T_C < Tth, `P_mm/d`, 0)) |>    # Long-term mean per HRU     group_by(Month, Station) |>    summarise(P_mmd = mean(P_mmd, na.rm = TRUE),              Rain_mmd = mean(Rain_mmd, na.rm = TRUE),              Snow_mmd = mean(Snow_mmd, na.rm = TRUE)) |>    # Sum per Basin   group_by(Month) |>    summarise(P_mmd = sum(P_mmd, na.rm = TRUE),              Rain_mmd = sum(Rain_mmd, na.rm = TRUE),              Snow_mmd = sum(Snow_mmd, na.rm = TRUE)) |>    ungroup() |>    dplyr::select(-P_mmd) |>    pivot_longer(-Month, names_to = \"Precipitation\", values_to = \"Values\") |>    mutate(Precipitation = ifelse(Precipitation == \"Rain_mmd\", \"Liquid\", \"Solid\")) |>    rename(Component = Precipitation)  forcing_plot <- ggplot(forcing) +    geom_col(aes(Month, Values, fill = Component), position = \"stack\") +    ylab(\"Precipitation [mm/d]\") +    scale_x_continuous(breaks = c(1:12),                       labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\",                                  \"O\", \"N\", \"D\")) +    theme_bw()   # Glacier discharge is already aggregated to sub-basin level  gl <- readResultCSV(paste0(data_path,                             \"RSMINERVE/Atbaschy_Results_Glacier_Sources.csv\")) |>   mutate(variable = \"Qgl\",           model = gsub(\"glaciers_\", \"\", model),           model = paste(toupper(substr(model, 1, 1)),                         substr(model, 2, nchar(model)), sep=\"\"),           Month = month(date)) |>    # Calculate mean flux per HRU   group_by(Month, variable, model) |>    summarise(value = mean(value), na.rm = TRUE) |>   # Sum over basin   group_by(Month, variable) |>    summarise(value = sum(value, na.rm = TRUE)) |>    ungroup() |>    mutate(variable = factor(variable,                             levels = c(\"Qgl\", \"Qr\", \"Qu\", \"Ql\")))  mean_monthly_fluxes <- fs |>    dplyr::filter(unit == \"m3/s\",                  date > as_date(\"1990-01-01\")) |>    mutate(Month = month(date)) |>    group_by(Month, variable, model) |>    summarise(value = mean(value), na.rm = TRUE) |>    group_by(Month, variable) |>    summarise(value = sum(value, na.rm = TRUE)) |>    ungroup() |>    mutate(variable = factor(variable,                             levels = c(\"Qgl\", \"Qr\", \"Qu\", \"Ql\"))) |>    add_row(gl)  discharge_plot <- ggplot(mean_monthly_fluxes) +    geom_area(aes(Month, value, fill = variable), position = \"stack\") +    scale_fill_viridis_d(name = \"Component\", direction = -1) +   ylab(\"Discharge [m3/s]\") +    scale_x_continuous(breaks = c(1:12),                       labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\",                                  \"O\", \"N\", \"D\")) +    theme_bw()    gridExtra::grid.arrange(forcing_plot, discharge_plot, ncol = 1)"},{"path":"/articles/03-RSMinerveIO.html","id":"flow-duration-curves","dir":"Articles","previous_headings":"Reading simulation results","what":"Flow duration curves","title":"I/O for RS Minerve","text":"last least modeler might wish produce flow duration curves based simulation results. Flow duration curves used, example, design hydraulic infrastructure. gray see flow duration curves individual years black mean flow duration curve.","code":"# Note: This example requires downloading of the example data and running of the code chunk above (section Reading & plotting results).  # Calculate the flow duration curve Qtot <- fs |>    dplyr::filter(unit == \"m3/s\",                  date > as_date(\"1990-01-01\")) |>    group_by(date) |>    summarise(Qtot_m3s = sum(value)) |>    ungroup()  fdc <- computeAnnualFlowDurationCurve(data = Qtot, column = \"Qtot_m3s\",                                        date = \"date\") |>    dplyr::filter(Ma <= 12) |>    mutate(Ma = as.numeric(Ma),           Year = factor(Year))  fdc_mean <- fdc |>    group_by(Ma) |>    summarise(Qtot_m3s = mean(Qtot_m3s)) |>    ungroup()    ggplot(fdc) +    geom_line(aes(Ma, Qtot_m3s, colour = Year), size = 0.6, alpha = 0.6,             show.legend = FALSE) +    geom_line(data = fdc_mean,              aes(Ma, Qtot_m3s)) +    ylab(\"Discharge [m3/s]\") +    xlab(\"Duration [months]\") +    scale_colour_manual(values = rep(\"gray\", length(unique(fdc$Year)))) +    scale_x_continuous(breaks = c(1:12),                       labels = c(1:12)) +    theme_bw()"},{"path":"/articles/04-glacier-functions.html","id":"background-motivation","dir":"Articles","previous_headings":"","what":"Background & Motivation","title":"Glacier utilities","text":"Central Asia region, key figures keep mind relation runoff formation: Snow melt important contribution discharge (~ 80 %, average), followed runoff liquid precipitation (~ 17 %, average) , finally, glacier melt (~ 3 %, average) (personal communication . Yakovlev, 2019). Armstrong et al. (2019) obtain similar orders magnitude 65%-75% snow melt, 23% precipitation 2-8% glacier melt basins rivers Syr Darya Amu Darya. smaller, highly glaciated catchments, glacier contribution discharge can important (Pohl et al. 2017; Dhaubanjar et al. 2021). cryosphere therefore major contributor water balance Central Asia (Barandun et al. 2020). glacier runoff small contributor annual runoff, seasonally important covers irrigation demand summer, snow melt (Kaser, Grosshauser, Marzeion 2010). Gaining proper understanding climate change impacts region’s hydrology just interest scientific community also greatest relevance local communities riparian states depend crucially availability runoff right time location. Among things, climate impacts translate long-term changes runoff formation fractions distribution runoff formation within hydrological year. Typical rainfall-runoff models HBV Model simulate fractionation precipitation snow rain temperature threshold method. Snow liquid water reservoirs corresponding fluxes accounted . However, models limited understanding glacier processes normally inadequate best estimate glacier contributions discharge. present short introduction glaciers water resources workflow include state---art glacier data scientific community day--day hydrological modelling.","code":""},{"path":"/articles/04-glacier-functions.html","id":"glaciers-in-water-resources-modelling","dir":"Articles","previous_headings":"","what":"Glaciers in Water Resources Modelling","title":"Glacier utilities","text":"Glaciers consist compacted snow frozen water. Many processes contribute glacier mass balance (see example Benn Evans (2010) Cogley et al. (2011)) focus simplified mass balance data accumulated mass balance outcomes (.e. glacier thinning rates glacier discharge, see ). Glacier mass balance components (thickness arrows scale) Cogley et al. (2011). Glaciers accumulate mass cold period higher altitudes snow fall. Glaciers lose mass melt driven energy balance glacier-atmosphere interface (Hock 2005). Typically, larger glaciers loose mass lower altitudes (ablation zone) accumulate mass higher altitudes (accumulation zone). mass loss lower altitudes compensated downstream movement ice accumulation zone. boundary accumulation ablation zone called equilibrium line altitude (ELA). Naturally, glaciers accumulate mass cold season loose mass ablation warm season. Therefore, overall mass balance glacier calculated year , better, average several years. simplified multi-year average glacier mass balance, neglecting snow melt, can expressed (Braithwaite Zhang 2000): \\[ \\Delta S = \\text{accumulation} - \\text{ablation} \\approx P - M \\] \\(\\Delta S\\) change water storage glacier, \\(P\\) precipitation glacier (assumed solid precipitation) \\(M\\) glacier melt. \\(\\Delta S\\) larger 0 (.e., \\(P > M\\)), glacier accumulates snow ice growing. \\(\\Delta S\\) smaller 0 (.e., \\(P < M\\)), imbalance ablation glacier shrinks. Glacier melt \\(M\\) can modeled using full energy balance models simplifications thereof, e.g. temperature index models (Hock 2003). simplified words, glacier, average, accumulates much snow looses melt, balance. average annual glacier discharge equivalent average annual snow fall called balance ablation. ELA move. glacier produces discharge accumulates snow fall, balance. ELA moves upwards. excess melt called imbalance ablation, also explained previous paragraph. snow falls melts, ELA moves downstream glacier grows (Cogley et al. 2011). Glacier graphics Anne Maussion, Atelier les Gros yeux, Open Global Glacier Model (OGGM). glaciers worldwide currently equilibrium warmer long-term average climate thus produce excess melt via imbalance ablation (Hugonnet et al. 2021). short term, example good semi-arid places Central Asia river discharge temporarily available downstream irrigation. However, glaciers produce excess melt reach new equilibrium higher altitudes disappear entirely. means excess melt also disappear ultimately less water available downstream users warm season glaciers contribute runoff. phenomenon called peak water (Huss Hock 2018). illustration peak water Huss Hock (2018). Water resources managers glaciated catchments highly interested knowing peak water reached measures adapt lower water availability need time implement. Without -situ measurements (actually even -situ measurements) easy feat model evolution water storage glacier. best can water resources modelling : Use results existing glacier models feed water resources model , alternatively, use best data available estimate glacier melt simple models. state---art glacier models available open source software (Maussion et al. 2019; Rounce, Hock, Shean 2020a), even simulation results published public use (Rounce, Hock, Shean 2020a), need implement glacier evolution model. New glacier thickness data sets can used update glacier-volume scaling relationships derived glaciers Central Asia. present vignette gives overview relevant glacier-related data, illustrated using catchment area river Atbashy, tributary Naryn river Central Asia (status mid 2022).","code":""},{"path":"/articles/04-glacier-functions.html","id":"availability-on-glacier-related-data","dir":"Articles","previous_headings":"","what":"Availability on glacier-related data","title":"Glacier utilities","text":"Recent advances glacier research yielded stupendous amount novel data sets can used map glaciers force glacier melt models. following section gives overview data used models, status January 2022. use catchment gauging station Atabshy river, tributary Naryn river Central Asia demo site. ’d like reproduce examples presented vignette can download zipped data clicking link. can extract downloaded data location choice adapt reference path code chunk . rest code run , provided required r packages installed. size data package approximately 1 GB.","code":"# Install the libraries required to reproduce this vignette # The below packages are available from cran and can be installed using the  # command install.packages. Example: install.packages(\"tmap\") library(tmap) library(sf) library(raster) library(tidyverse) library(lubridate)  # The package riversCentralAsia is not available from cran. It is installed  # directly from github via:  devtools::install_github(\"hydrosolutions/riversCentralAsia\") # Make sure to update the package from time to time as it is under constant  # development.  library(riversCentralAsia)  # Path to the data directory downloaded from the download link provided above.  # Here the data is extracted to a folder called atbashy_glacier_demo_data data_path <- \"../../atbashy_glacier_demo_data/\""},{"path":"/articles/04-glacier-functions.html","id":"randolph-glacier-inventory","dir":"Articles","previous_headings":"Availability on glacier-related data","what":"Randolph glacier inventory","title":"Glacier utilities","text":"Randolph Glacier Inventory (RGI) v6.0 (RGI Consortium 2017) makes consistent global glacier data base publicly available. includes geo-located glacier geometry additional parameters, example elevation, length, slope aspect. new version (v7) review time writing mid 2022. Central Asian water resources modelling, RGI regions 13 (Central Asia) 14 (South Asia West) relevant. can download glacier geometries RGI regions GLIMS RGI v6.0 web site. demo, data available data download link given . Note: python package rgitools provides functions pre-processing RGI glacier outlines, automated data quality checks glacier hypsometry data1.","code":"dem <- raster(paste0(data_path, \"GIS/16076_DEM.tif\")) basin <- st_read(paste0(data_path, \"GIS/16076_Basin_outline.shp\"), quiet=TRUE)  rgi <- st_read(paste0(data_path, \"GIS/16076_Glaciers_per_subbasin.shp\"),                 quiet = TRUE) |>    st_transform(crs = crs(dem))  tmap_mode(\"view\") tm_shape(dem, name = \"DEM\") +   tm_raster(n = 6,              palette = terrain.colors(6),             alpha = 0.8,             legend.show = TRUE,              title = \"Elevation (masl)\") +    tm_shape(rgi, name = \"RGI v6.0\") +    tm_polygons(col = \"lightgray\", lwd = 0.2) +    tm_scale_bar(position = c(\"right\", \"bottom\"))"},{"path":"/articles/04-glacier-functions.html","id":"glacier-thickness","dir":"Articles","previous_headings":"Availability on glacier-related data","what":"Glacier thickness","title":"Glacier utilities","text":"Two global glacier thickness datasets currently publicly available: Farinotti et al. (2019a) Milan, Mouginot, Rabatel (2021). Farinotti et al. (2019b) make distributed glacier thickness maps available glacier RGI v6 data set individual tifs. Millan et al. (2022) provide one tif RGI region convenient handle.","code":"thickness <- raster(paste0(data_path,                             \"GLACIERS/Milan_glacier_thickness.tif\"))  values(thickness)[values(thickness) <= 0] = NA  tmap_mode(\"view\") tm_shape(dem, name = \"DEM\") +   tm_raster(n = 6,              palette = terrain.colors(6),             alpha = 0.8,             legend.show = TRUE,              title = \"Elevation (masl)\") +    tm_shape(thickness, name = \"Thickness\") +    tm_raster(n = 6,              palette = \"Blues\",              title = \"Thickness [m]\") +    tm_scale_bar(position = c(\"right\", \"bottom\"))"},{"path":"/articles/04-glacier-functions.html","id":"glacier-area-volume-scaling","dir":"Articles","previous_headings":"Availability on glacier-related data","what":"Glacier area-volume scaling","title":"Glacier utilities","text":"Well-established methods exist derive outlines glaciers remote sensing data (RGI Consortium 2017), .e. glacier areas relatively well known (global scale). recently, glacier volumes available wider public scaling relationships used derive glacier volumes based glacier area length, example (Bahr, Meier, Peckham 1997; Van de Wal Wild 2001; Radić Hock 2006). although scaling relationships derived glaciers presumably steady-state conditions, Radić, Hock, Oerlemans (2007) found suitable long-term glacier development. Central Asia, scaling relationship Erasov (1968) widely applied method, empirical function form: \\[ V = \\cdot ^{b} \\] \\(=0.027\\) \\(b=1.5\\). Using RGI v6.0 glacier outlines region 13 (Central Asia) glacier thickness data set Farinotti et al. (2019b), volume glacier can estimated area-volume scaling Erasov (1968) can validated (see CAHAM book). relationship derived Erasov still valid glaciers 20 km2, may overestimate glacier volume larger glaciers. Using novel data, parameters empirical scaling function derived Erasov (1968) can updated \\(=0.0388\\) \\(b=1.262\\) form call RGIF scaling relationship. scaling relationship can inverted derive glacier areas based glacier volumes : \\[ =\\exp{\\left(\\frac{\\left(\\log{V} - \\log{}\\right)}{b}\\right)} \\] package riversCentralAsia implements area-volume scaling volume-area scaling parameter sets Erasov derived RGI Consortium (2017) Farinotti et al. (2019b) functions glacierArea_Erasov(), glacierArea_RGIF(), glacierVolume_Erasov() glacierVolume_RGIF(). scaling functions derive glacier area volume based glacier length published Aizen, Aizen, Kuzmichonok (2007). empirical equations derived glaciers Tien Shan mountains implemented glacierAreaVolume_Aizen() riversCentralAsia package. Aizen computes glacier Area \\(\\) glacier length \\(L\\) follows: \\[=\\left(\\frac{L}{1.6724}\\right)^{\\frac{1}{0.561}}\\] glacier volume \\(V\\) depeding glacier area: \\[V=0.03782 \\cdot ^{1.23}\\text{ }\\text{ }\\text{ }\\text{ }\\text{ } <0.1\\text{ km}^2\\] \\[V=\\frac{\\left(0.03332 \\cdot ^{1.08} \\cdot e^{0.1219 \\cdot L}\\right)}{L^{0.08846}}\\text{ }\\text{ }\\text{ }\\text{ }\\text{ } 0.1 < < 25\\text{ km}^2\\] \\[V=0.018484 \\cdot + 0.021875 \\cdot ^{1.3521}\\text{ }\\text{ }\\text{ }\\text{ }\\text{ } > 25\\text{ km}^2\\]","code":""},{"path":"/articles/04-glacier-functions.html","id":"glacier-runoff","dir":"Articles","previous_headings":"Availability on glacier-related data","what":"Glacier runoff","title":"Glacier utilities","text":"Rounce, Hock, Shean (2020a) published simulated projections glacier runoff till 2100 average CMIP5 GCM model ensemble2 RCPs3. used model PyGEM (Python Glacier Evolution Model) available via GitHub. data can accessed Rounce, Hock, Shean (2020b).","code":""},{"path":[]},{"path":"/articles/04-glacier-functions.html","id":"glacier-thinning-rates","dir":"Articles","previous_headings":"Availability on glacier-related data > Further data that can be used for cross-validation","what":"Glacier thinning rates","title":"Glacier utilities","text":"Hugonnet et al. (2021) provide annual estimates glacier thinning rates glacier RGI v6.0 data set. copy Hugonnet thinning rates included download link . per-glacier time series thinning rates available data repository described github site linked code availability section online paper Hugonnet et al. (2021). Glacier thinning rates can viewed net glacier mass change glacier imbalance ablation (glacier ice deformation processes neglected).","code":"hugonnet <- read_csv(paste0(data_path, \"/GLACIERS/Hugonnet/dh_13_rgi60_pergla_rates.csv\"))  # Explanation of variables: # - dhdt is the elevation change rate in meters per year, # - dvoldt is the volume change rate in meters cube per year, # - dmdt is the mass change rate in gigatons per year, # - dmdtda is the specific-mass change rate in meters water-equivalent per year.  # Filter the basin glaciers from the Hugonnet data set.  hugonnet <- hugonnet |>    dplyr::filter(rgiid %in% rgi$RGIId) |>    tidyr::separate(period, c(\"start\", \"end\"), sep = \"_\") |>    mutate(start = as_date(start, format = \"%Y-%m-%d\"),           end = as_date(end, format = \"%Y-%m-%d\"),           period = round(as.numeric(end - start, units = \"days\")/366))  # Join the Hugonnet data set to the RGI data set to be able to plot the thinning  # rates on the glacier geometry.  glaciers_hugonnet <- rgi |>    left_join(hugonnet |> dplyr::select(rgiid, area, start, end, dhdt, err_dhdt,                                        dvoldt, err_dvoldt, dmdt, err_dmdt,                                        dmdtda, err_dmdtda, period),               by = c(\"RGIId\" = \"rgiid\"))   tmap_mode(\"view\") tm_shape(dem, name = \"DEM\") +    tm_raster(n = 6,              palette = terrain.colors(6),             alpha = 0.8,              legend.show = TRUE,              title = \"Elevation (masl)\") +    tm_shape(glaciers_hugonnet |> dplyr::filter(period == 20),             name = \"Thinning [m weq/a]\") +   tm_fill(col = \"dmdtda\",            n = 6,            palette = \"RdBu\",           midpoint = 0,            legend.show = TRUE,            title = \"Glacier thinning\\n(m weq/a)\") +    tm_shape(rgi, name = \"RGI v6.0\") +    tm_borders(col = \"gray\", lwd = 0.4) +    tm_shape(basin, name = \"Basin outline\") +    tm_borders(col = \"black\", lwd = 0.6) +    tm_scale_bar(position = c(\"right\", \"bottom\"))"},{"path":"/articles/04-glacier-functions.html","id":"glacier-discharge","dir":"Articles","previous_headings":"Availability on glacier-related data > Further data that can be used for cross-validation","what":"Glacier discharge","title":"Glacier utilities","text":"Miles et al. (2021) ran specific mass balance calculations many glaciers larger 2 km2 High Mountain Asia. provide average glacier discharge 2000 2016. copy glacier discharge data available data download link provided . original data available data repository linked online version paper. hydrological applications, interest lies glacier discharge, .e. total ablation glaciers. Despite large uncertainties, simulation results Miles et al. (2021) give us estimate glacier melt can use calibrate simpler temperature index models glacier melt.","code":"miles <- read_delim(paste0(data_path,                            \"GLACIERS/Miles/Miles2021_Glaciers_summarytable_20210721.csv\"),                     show_col_types = FALSE, delim = \",\") |>    dplyr::filter(RGIID %in% rgi$RGIId & VALID == 1)  glaciers_hugonnet <- glaciers_hugonnet |>    left_join(miles |> dplyr::select(RGIID, totAbl, totAblsig, imbalAbl,                                     imbalAblsig),              by = c(\"RGIId\" = \"RGIID\")) |>    mutate(Qgl_m3a = ifelse(is.na(totAbl), NA, totAbl))  tmap_mode(\"view\") tm_shape(dem, name = \"DEM\") +    tm_raster(n = 6,              palette = terrain.colors(6),             alpha = 0.8,              legend.show = TRUE,              title = \"Elevation (masl)\") +    tm_shape(glaciers_hugonnet |> dplyr::filter(period == 20),             name = \"Total ablation [m3/a]\") +   tm_fill(col = \"Qgl_m3a\",            n = 6,            palette = \"RdBu\",           midpoint = 0,            legend.show = TRUE,            title = \"Glacier discharge\\n(m3/a)\") +    tm_shape(rgi, name = \"RGI v6.0\") +    tm_borders(col = \"gray\", lwd = 0.4) +    tm_shape(basin, name = \"Basin outline\") +    tm_borders(col = \"black\", lwd = 0.6) +    tm_scale_bar(position = c(\"right\", \"bottom\"))"},{"path":"/articles/04-glacier-functions.html","id":"a-note-on-the-uncertainties-of-glacier-data-sets","dir":"Articles","previous_headings":"Availability on glacier-related data","what":"A note on the uncertainties of glacier data sets","title":"Glacier utilities","text":"geometries RGI v6.0 data set generally good. simulate glacier discharge small catchment glaciers advisable visually check glacier geometries make sure, relevant glaciers basin included RGI data set. may manually add missing glaciers correct geometry. regions Central Asia, OpenStreetMap excellent reference glacier locations names Central Asia. can import map layer QGIS also download individual. glacier thickness data set validated locations measurements glacier thickness typically available. Millan et al. (2022) report uncertainty ice volume estimations 39% RGI regions 13, 14 15 (High Mountain Asia). Hugonnet et al. (2021) & Miles et al. (2021) provide uncertainties estimates per-glacier glacier thinning & discharge rates data set .","code":""},{"path":[]},{"path":[]},{"path":"/articles/05-snow-calibration.html","id":"calibrating-snow-water-equivalent-swe","dir":"Articles","previous_headings":"","what":"Calibrating snow water equivalent (SWE)","title":"Manual calibration of snow water equivalent","text":"time writing, RS Minerve support automatic calibration SWE. However, snow melt major contribution discharge Central Asia. Measurements SWE rarely available. Thus, re-analysis products like High Mountain Asia Snow Reanalysis product valuable resources validate hydrolgoical modelling efforts. automated calibration SWE yet supported RS Minerve, propose work around R iteratively adapt parameters HBV snow modules.","code":""},{"path":"/articles/05-snow-calibration.html","id":"extract-observed-swe","dir":"Articles","previous_headings":"Calibrating snow water equivalent (SWE)","what":"Extract observed SWE","title":"Manual calibration of snow water equivalent","text":"Actually observed SWE typically available hydrological modeling many catchments Central Asia, therefore propose use existing model products like High Mountain Snow Reanalysis Product (Liu, Fang, Margulis 2021) available NSIDC. Login USGS Earth Data, select files download model area download data (example using python download script). refer SWE data set HMASR observed data. downloaded data subsequently pre-processed extract daily average SWE per HRU valid pixels data set (note HMASR available areas permanent snow ice cover). following code sniped shows can done. wish reproduce code , please make sure demo data set downloaded computer. find 4 sample files HMASR product available Atbashy demo data folder try code . done pre-processesing Atbashy make available SWE.RData file contains daily average SWE per HRU Atbashy model.","code":"library(tmap) library(sf) library(raster) library(tidyverse) library(lubridate)  devtools::install_github(\"hydrosolutions/riversCentralAsia\") library(riversCentralAsia)  # Download the demo data set from dropbox # https://www.dropbox.com/sh/r0lqggc77ka0uxd/AAChuIyLHHFIfAdgxNKiU2dpa?dl=0  # Path to the data directory downloaded from the download link provided above.  # Here the data is extracted to a folder called atbashy_glacier_demo_data data_path <- \"../../atbashy_glacier_demo_data/\"  # Function to concatenate and mask the HMASR product and extract SWE for each  # HRU in the model.  extract_HMASR_Atbashy <- function(filespath, year, shape_latlon, varname) {   index = sprintf(\"%02d\", (year - 1999))      # Load non-seasonal snow mask   filepart <- \"_MASK.nc\"      # The Atbashy basin is covered by two raster stacks   mask_w <- raster::brick(paste0(filespath,                                   \"HMA_SR_D_v01_N41_0E76_0_agg_16_WY\",                                   year, \"_\", index, filepart),                            varname = \"Non_seasonal_snow_mask\")   raster::crs(mask_w) = raster::crs(\"+proj=longlat +datum=WGS84 +no_defs\")   mask_e <- raster::brick(paste0(filespath,                                  \"HMA_SR_D_v01_N41_0E77_0_agg_16_WY\",                                   year, \"_\", index, filepart),                            varname = \"Non_seasonal_snow_mask\")   raster::crs(mask_e) = raster::crs(\"+proj=longlat +datum=WGS84 +no_defs\")      # The rasters need to be rotated   template <- raster::projectRaster(from = mask_e, to= mask_w, alignOnly = TRUE)      # template is an empty raster that has the projected extent of r2 but is    # aligned with r1 (i.e. same resolution, origin, and crs of r1)   mask_e_aligned <- raster::projectRaster(from = mask_e, to = template)   mask_w <- flip(t(mask_w), direction = 'x')   mask_e_aligned <- flip(t(mask_e_aligned), direction = 'x')   mask <- merge(mask_w, mask_e_aligned, tolerance = 0.1)    mask = raster::projectRaster(from = mask,                                 crs = crs(\"+proj=utm +zone=42 +datum=WGS84 +units=m +no_defs\"))      # Load snow data   varname = \"SWE_Post\"   filepart <- \"_SWE_SCA_POST.nc\"   sca_w <- raster::brick(paste0(filespath,                                  \"HMA_SR_D_v01_N41_0E76_0_agg_16_WY\",                                  year, \"_\", index, filepart),                           varname = varname, level = 1)      raster::crs(sca_w) = raster::crs(\"+proj=longlat +datum=WGS84 +no_defs\")   sca_e <- raster::brick(paste0(filespath,                                 \"HMA_SR_D_v01_N41_0E77_0_agg_16_WY\",                                  year, \"_\", index, filepart),                           varname = varname, level = 1)      raster::crs(sca_e) = raster::crs(\"+proj=longlat +datum=WGS84 +no_defs\")   template <- raster::projectRaster(from = sca_e, to = sca_w, alignOnly = TRUE)   # template is an empty raster that has the projected extent of r2 but is    # aligned with r1 (i.e. same resolution, origin, and crs of r1)   sca_e_aligned<- raster::projectRaster(from = sca_e, to = template)   sca_w <- flip(t(sca_w), direction = 'x')   sca_e_aligned <- flip(t(sca_e_aligned), direction = 'x')   sca <- raster::merge(sca_w, sca_e_aligned, tolerance = 0.1)   sca <- projectRaster(from = sca,                         crs = crs(\"+proj=utm +zone=42 +datum=WGS84 +units=m +no_defs\"))      sca_masked <- mask(sca, mask, maskvalue = 1)   sca_masked <- mask(sca_masked, basin)      subbasin_data_a <- raster::extract(sca, shape_latlon, fun = mean,                                       na.rm = TRUE, method = \"bilinear\")    subbasin_data <- subbasin_data_a %>% t() %>% as_tibble()    names(subbasin_data) <- shape_latlon$name   subbasin_data <- subbasin_data %>%     mutate(HyDOY = c(1:dim(subbasin_data_a)[2]),             HyYear = year)      return(subbasin_data) }  # Load additional necessary data dem <- raster(paste0(data_path, \"GIS/16076_DEM.tif\")) basin <- st_read(paste0(data_path, \"GIS/16076_Basin_outline.shp\"),                   quiet = TRUE) shape_latlon <- st_read(paste0(data_path, \"GIS/16076_HRU.shp\")) |>    st_transform(crs = crs(\"+proj=longlat +datum=WGS84 +no_defs\"))  # Load one example file and display SWE for a random date in the cold season.  filespath <- paste0(data_path, \"SNOW/\")  # Actual data extraction varname = \"SWE_Post\" year = 1999 swe <- extract_HMASR_Atbashy(filespath, year, shape_latlon, varname)  # The subsequent years of data you can extract in a loop.  # Not run in this example as we provide you only with the first year of data # Later years you can download from NSIDC # for (year in 2000:2012) {  #   temp <- extract_HMASR_Atbashy(filespath, year, shape_latlon, varname) #   swe <- rbind(swe, temp) # }  # Reformatting  swe$NoDaysPerYear <- as.numeric(   format(as.Date(paste(swe$HyYear, \"12\", \"31\", sep=\"-\")), \"%j\")) swe <- swe %>%   mutate(DOY = ifelse(     HyDOY > (NoDaysPerYear - yday(as_date(paste0(HyYear, \"-10-01\")))),     HyDOY - (NoDaysPerYear - yday(as_date(paste0(HyYear, \"-10-01\")))),     HyDOY - 1 + yday(as_date(paste0(HyYear, \"-10-01\")))))  swe <- swe %>%   mutate(Year = ifelse(HyDOY < DOY, HyYear, HyYear + 1)) swe$HyYear <- swe$HyYear + 1  swe$Date <- as_date(paste0(swe$Year, \"-\", swe$DOY), format = \"%Y-%j\")  swel <- pivot_longer(swe, contains(\"_\"), names_to = \"Name\",                       values_to = \"SWE\") |>    separate(Name, into = c(\"Subbasin\", \"layer\"), sep = \"_Subbasin_\",             remove = FALSE) |>    mutate(layer = factor(layer, levels = c(10:1)))  # As this data extraction can take several minutes, we store the snow water  # equivalents in an RData file for later use.  # save(list = \"swel\", file = \"SWE.RData\")"},{"path":"/articles/05-snow-calibration.html","id":"write-check-node-file-to-read-out-all-swe-in-the-atbashy-model-","dir":"Articles","previous_headings":"Calibrating snow water equivalent (SWE)","what":"Write check node file to read out all SWE in the Atbashy model.","title":"Manual calibration of snow water equivalent","text":"Data can exported RS Minerve various methods. manual export SWE model results larger model can become time consuming, therefore RS Minerve offers possibility import called check node file specify selection model variables export. code snipped shows write check node file extracting SWE simulation results RS Minerve. RS Minerve selection plots tab, import check node file SWE.chk written plot data. export data file read RStudio .","code":"Object_IDs <- st_read(paste0(data_path,                               \"GIS/16076_HRU.shp\")) |>    st_drop_geometry()   data <- tibble(   Model = rep(\"Model Atbashy\", length(Object_IDs$name)),    Object = c(rep(\"HBV92\", length(Object_IDs$name))),    ID = Object_IDs$name,    Variable = rep(\"SWE (m)\") )  writeSelectionCHK(filepath = paste0(data_path, \"RSMINERVE/SWE.chk\"),                    data = data,                    name = \"SWE\")"},{"path":"/articles/05-snow-calibration.html","id":"read-rs-minerve-swe-results","dir":"Articles","previous_headings":"Calibrating snow water equivalent (SWE)","what":"Read RS Minerve SWE results","title":"Manual calibration of snow water equivalent","text":"read simulated SWE produced initial parameter set created without taking account SWE observations. data can used manually validate SWE secondary data sources like example High Mountain Asia Snow Reanalysis Product (Liu et al., 2021. https://doi.org/10.5067/HNAUGJQXSCVU).","code":"swe_sim <- readResultCSV(   paste0(data_path,           \"RSMINERVE/Atbaschy_Results_SWE_initial_params.csv\")) |>     mutate(Subbasin = gsub(\"\\\\_Subbasin\\\\_\\\\d+$\", \"\", model),           \"Elevation band\" = str_extract(model, \"\\\\d+$\") |> as.numeric(),           \"Elevation band\" = factor(`Elevation band`, levels = c(1:20)))  ggplot(swe_sim) +    geom_point(aes(date, value, colour = `Elevation band`), alpha = 0.4, size = 0.4) +    scale_colour_viridis_d() +    facet_wrap(\"Subbasin\") +    theme_bw()"},{"path":"/articles/05-snow-calibration.html","id":"read-in-observations-of-snow-water-equivalent","dir":"Articles","previous_headings":"Calibrating snow water equivalent (SWE)","what":"Read in observations of snow water equivalent","title":"Manual calibration of snow water equivalent","text":"data downloaded pre-processed (see ). Now can adjust parameters snow modules HBV model objects RS Minerve iteratively improve fit observed simulated snow water equivalent. can also write HMASR data csv file (see chunk ) import RS Minerve time series comparison facilitate manual calibration.","code":"# Loads SWE extracted from HMASR per HRU in the Atbashy model.  # For the sake of simplicity, we have extracted the SWE data for the Atbashy  # example.  # See the code chunk above under \"Extract observed SWE\" for an example of how  # to extract SWE from the HMASR product yourselve.  load(paste0(data_path, \"/SNOW/SWE.RData\"))  compare_swe <- swe_sim |>    rename(Sim = value) |>    dplyr::select(date, model, Sim, Subbasin, `Elevation band`) |>    left_join(swel |>                dplyr::select(Date, Name, SWE) |>                rename(Obs = SWE),              by = c(\"date\" = \"Date\", \"model\" = \"Name\")) |>   mutate(Month = month(date),           Year = hyear(date),           Month_str = factor(format(date, \"%b\"),                              levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\",                                         \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\",                                         \"Nov\", \"Dec\")),           \"Obs-Sim\" = Obs - Sim)  RMSE = sqrt(mean(compare_swe$`Obs-Sim`, na.rm = TRUE))  ggplot(compare_swe) +   geom_abline(intercept = 0, slope = 1) +    geom_point(aes(Obs, Sim), size = 0.4) +   scale_color_viridis_d() +    xlab(\"Observed SWE [m]\") +    ylab(\"Simulated SWE [m]\") +    coord_fixed() + xlim(0, 1.5) + ylim(0, 1.5) +    theme_bw() ggplot(compare_swe) +   geom_abline(intercept = 0, slope = 1) +    geom_point(aes(Obs, Sim, colour = `Elevation band`), size = 0.4) +   scale_color_viridis_d() +    xlab(\"Observed SWE [m]\") +    ylab(\"Simulated SWE [m]\") +    facet_wrap(\"Month_str\") +    coord_fixed() + xlim(0, 1.5) + ylim(0, 1.5) +    theme_bw() # Generate date sequence in accordance with RSMinerve Requirements dates <- tibble(Date = swel$Date |> unique()) datesChar <- posixct2rsminerveChar(dates$Date, tz = \"UTC\") |>    rename(Station = value) |>    mutate(Station = gsub(\" 02:00\", \" 00:00\", Station),           Station = gsub(\" 01:00\", \" 00:00\", Station))  # Get names of HRUs df_body <- swel |>   dplyr::select(Date, Name, SWE) |>    distinct() |>    pivot_wider(names_from = Name, values_from = SWE, values_fn = \"mean\") |>    dplyr::select(-Date)  # Construct csv-file header.   # See the definition of the RSMinerve .csv database file at: # https://www.youtube.com/watch?v=p4Zh7zBoQho header_Station <- tibble(   Station = c('X','Y','Z','Sensor','Category','Unit','Interpolation'))  # Get random X and Y coordinate, they are not relevant for the model but we need # an entry for importing the file to RS Minerve.  HRU_XYZ <- matrix(0, nrow = 3, ncol = dim(df_body)[2]) |> as.data.frame()  names(HRU_XYZ) <- names(df_body)  # Sensor (SWE), Category, Unit and Interpolation nBands <- HRU_XYZ |> dim() |> dplyr::last() sensorType <- rep(\"SWE\", nBands) unit <- rep(\"m\", nBands) category <- rep(\"Snow depth\", nBands) interpolation <- rep(\"linear\", nBands) sensor <- rbind(sensorType, category, unit, interpolation) |> as_tibble() names(sensor) <- names(df_body)  # Put everything together file2write <- rbind(HRU_XYZ, sensor) file2write <- header_Station |> add_column(file2write) file2write <- file2write |> add_row(cbind(datesChar, df_body) |>                                        mutate_all(as.character)) file2write <- rbind(names(file2write), file2write)  # Write file to disk write_csv(file2write, paste0(data_path, \"RSMINERVE/SWEobs.csv\"),            col_names = FALSE)"},{"path":"/articles/05-snow-calibration.html","id":"view-swe-simulation-results-after-manual-calibration","dir":"Articles","previous_headings":"Calibrating snow water equivalent (SWE)","what":"View SWE simulation results after manual calibration","title":"Manual calibration of snow water equivalent","text":"use SWE HMASR product improves hydrological model.","code":"swe_sim <- readResultCSV(   paste0(data_path,           \"RSMINERVE/Atbaschy_Results_SWE_manual_cal.csv\")) |>    mutate(Subbasin = gsub(\"\\\\_Subbasin\\\\_\\\\d+$\", \"\", model),           \"Elevation band\" = str_extract(model, \"\\\\d+$\") |> as.numeric(),           \"Elevation band\" = factor(`Elevation band`, levels = c(1:20)))  load(paste0(data_path, \"/SNOW/SWE.RData\"))  compare_swe <- swe_sim |>    rename(Sim = value) |>    dplyr::select(date, model, Sim, Subbasin, `Elevation band`) |>    left_join(swel |>                dplyr::select(Date, Name, SWE) |>                rename(Obs = SWE),              by = c(\"date\" = \"Date\", \"model\" = \"Name\")) |>   mutate(Month = month(date),           Year = hyear(date),           Month_str = factor(format(date, \"%b\"),                              levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\",                                         \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\",                                         \"Nov\", \"Dec\")),           \"Obs-Sim\" = Obs - Sim)  RMSE = sqrt(mean(compare_swe$`Obs-Sim`, na.rm = TRUE))  ggplot(compare_swe) +   geom_abline(intercept = 0, slope = 1) +    geom_point(aes(Obs, Sim), size = 0.4) +   scale_color_viridis_d() +    xlab(\"Observed SWE [m]\") +    ylab(\"Simulated SWE [m]\") +    coord_fixed() + xlim(0, 1.5) + ylim(0, 1.5) +    theme_bw() ggplot(compare_swe) +   geom_abline(intercept = 0, slope = 1) +    geom_point(aes(Obs, Sim, colour = `Elevation band`), size = 0.4) +   scale_color_viridis_d() +    xlab(\"Observed SWE [m]\") +    ylab(\"Simulated SWE [m]\") +    facet_wrap(\"Month_str\") +    coord_fixed() + xlim(0, 1.5) + ylim(0, 1.5) +    theme_bw()"},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tobias Siegfried. Maintainer, author.            hydrosolutions GmbH, www.hydrosolutions.ch Beatrice Marti. Author.            hydrosolutions GmbH, www.hydrosolutions.ch","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Siegfried T, Marti B (2022). riversCentralAsia: Accompanying R Package Applied Modeling Hydrological Systems Central Asia Course. R package version 1.1.0, https://hydrosolutions.github.io/riversCentralAsia/index.html.","code":"@Manual{,   title = {riversCentralAsia: Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course},   author = {Tobias Siegfried and Beatrice Marti},   year = {2022},   note = {R package version 1.1.0},   url = {https://hydrosolutions.github.io/riversCentralAsia/index.html}, }"},{"path":[]},{"path":"/index.html","id":"summary","dir":"","previous_headings":"","what":"Summary","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"R package riversCentralAsia includes set tools facilitate automate data preparation hydrological modelling. thus contributes reproducible modeling workflows makes hydrological modeling accessible students interested professional modelers. package developed within frame master level course applied hydrological modelling Central Asia extensively used open-source book Modeling Hydrological Systems Semi-Arid Central Asia (Siegfried & Marti, 2022). workflows validated within Horizon 2020 project HYDRO4U. package developed Central Asia region, functions generic can used modelling projects anywhere world. important functionalities package well raw data can processed package described articles project documentation site examples book Modeling Hydrological Systems Semi-Arid Central Asia demonstrate full range functions available use workflow.","code":""},{"path":"/index.html","id":"statement-of-need","dir":"","previous_headings":"","what":"Statement of need","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"Data preparation comes hydrological modelling actually one biggest work chunks modelling process. package includes number helper functions can connected efficient workflows automatize data preparation process hydrological modelling shown figure .  Figure: Overview modelling workflow supported riversCentralAsia package (Image source: Marti et al., 2022). Abbreviations explained . workflow relies entirely free, publicly available data software. data preparation step includes delineation river catchment boundaries derivation hydrological response units (HRU) using gauge locations, SRTM digital elevation model (DEM) glacier outlines Randolph Glacier Inventory (RGI). Although High Mountain region Central Asia generally perceived data scarce region, number gridded data products available form fair basis regional hydrological modelling seasonal time scales. CHELSA v2.1 weather data product 1 km2 1km2 resolution. Glacier thinning glacier ablation data sets open-access literature. Data snow water equivalents sourced High Mountain Asia Snow Reanalysis (HMASR) Product, river discharge taken hydrological year books HydroMeteorological Institutes Central Asia, CMIP6 climate model results area available Copernicus. Hydrological modelling done using free hydrologic-hydraulic modelling software RS Minerve. alternative geoprocessing workflows described QGIS. riversCentralAsia package functionality includes: Efficient processing present future climate forcing, including hydro-meterological data Central Asia (time series re-analysis data) -scaling ERA5 re-analysis data (advanced topic described course book) preparation GIS layers automated model generation chapter Geospatial data course book Volume area scaling glaciers Post-processing simulation results, e.g. extraction visualisation snow water equivalent computation flow duration curves /O interface hydrologic-hydraulic modelling software allows reading writing input output files hydraulic-hydrological modelling software RS Minerve. , focus description individual functions, strengths package comes play mostly functions connected automatize data preparation process. workflows extensively documented book Modeling Hydrological Systems Semi-Arid Central Asia. Currently, relatively complete dataset Chirchik River Basin decadal monthly data discharge, precipitation temperature included.","code":""},{"path":"/index.html","id":"related-packages","dir":"","previous_headings":"","what":"Related packages","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"hydraulic-hydrological modelling software RS MINERVE can accessed Common Language Runtime (CLR) directly within R, thus use RS MINERVE GUI can avoided multiple runs large models can speed . github repository RSMinerveR includes examples use CLR commands use Visual Basic interface RS MINERVE documented technical manual. functionality recommended advanced users RS MINERVE .","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"package many dependencies installed alongside riversCentralAsia. successfully install package need prior installations following packages: rlang, magrittr, stringr purrr. installation fail, test following dependencies installed. yet available system, please install using following commands. dependencies installed automatically. Note Mac users may install binary version dependency package exactextractr manually (recent source version). Note Windows users require working installation RTools install packages github. can install development version GitHub : recommend testing riversCentralAsia package using make sure dependencies integrate riversCentralAsia package . following step--step instructions explain : Go packages github repository, click green code button select download zip. download zip folder package code Download folder. Extract package files location preference. detailed instructions step: right-click zip folder select “extract ”pop-window. Select location extract files wait process finish. Navigate riversCentralAsia folder freshly downloaded package data stored open riversCentralAsia R project file. open project R GUI. R console, type devtools::test() hit enter. tests run minute. test return [ FAIL 0 | WARN 0 | SKIP 0 | PASS 86 ] end, test successful package run without problems system. one tests fail, please make sure package dependencies date. problem persists, please file issue including error message get can look problem hopefully solve . don’t need source codes , can safely delete zip file folder extracted riversCentralAsia files.","code":"find.package(c(\"rlang\", \"magrittr\", \"stringr\", \"purrr\")) install.packages(c(\"rlang\", \"magrittr\", \"stringr\", \"purrr\")) # install.packages(\"devtools\") devtools::install_github(\"hydrosolutions/riversCentralAsia\") library(riversCentralAsia)"},{"path":"/index.html","id":"community-guidelines","dir":"","previous_headings":"","what":"Community guidelines","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"Please consult documentation examples provided package documentation open-source course book Modeling Hydrological Systems Semi-Arid Central Asia. problems using functions suggestions, please use issue tool.","code":""},{"path":"/index.html","id":"how-to-cite","dir":"","previous_headings":"","what":"How to cite","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"Please cite package : Tobias Siegfried, & Beatrice Marti (2021): riversCentralAsia . https://doi.org/10.5281/zenodo.4667422","code":""},{"path":"/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"basic example shows visualize included data.","code":"library(riversCentralAsia) library(tidyverse) library(timetk)  # Loading and visualising discharge data ChirchikRiverBasin  # load data ChirchikRiverBasin |>    # Filter for the data type, here discharge \"Q\"   dplyr::filter(type == \"Q\") |>    drop_na() |>    group_by(river) |>    plot_time_series(     date,     data,     .interactive = FALSE,     .facet_ncol = 2,     .smooth = FALSE,      .y_lab = \"Discharge [m3/s]\",      .x_lab = \"Year\",      .title = \"Discharge time series in the ChirchikRiverBasin data set\"     )"},{"path":"/index.html","id":"mentions","dir":"","previous_headings":"","what":"Mentions","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"package used extensively course book Modeling Hydrological Systems Semi-Arid Central Asia (Siegfried & Marti, 2022). workflows presented course book, using riversCentralAsia package, validated within Horizon 2020 project HYDRO4U future small hydro power potential evaluated using hydrological modelling. R & RS Minerve users, package RSMinverveR recommended allows interfacing R RS Minerve (examples based Visual Basic Script examples CREALP).","code":""},{"path":"/index.html","id":"acknowledgement","dir":"","previous_headings":"","what":"Acknowledgement","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"preparation course book thus preparation package financially supported Swiss Agency Development Cooperation, German Kazakh University Almaty hydrosolutions. R package submitted Journal Open Source Software. thank @tonyewong @mengqi-z valuable inputs review package @crvernon editing work.","code":""},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Accompanying R Package to Applied Modeling of Hydrological Systems in Central Asia Course","text":"Tobias Siegfried & Beatrice Marti (2022): Modeling Hydrological Systems Semi-Arid Central Asia (https://hydrosolutions.github.io/caham_book/). DOI: 10.5281/zenodo.6350042 Marti, B. S., Zhumabaev, ., Siegfried, T.: comprehensive open-source course teaching applied hydrological modelling Central Asia, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2022-966, 2022.","code":""},{"path":"/reference/ChirchikRiverBasin.html","id":null,"dir":"Reference","previous_headings":"","what":"Discharge, precipitation and temperature in the Chirchik river basin,\nUzbekistan. — ChirchikRiverBasin","title":"Discharge, precipitation and temperature in the Chirchik river basin,\nUzbekistan. — ChirchikRiverBasin","text":"dataset containing 10-day (decadal) monthly data discharge, precipitation temperature Chirchiq river basin, Uzbekistan.","code":""},{"path":"/reference/ChirchikRiverBasin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discharge, precipitation and temperature in the Chirchik river basin,\nUzbekistan. — ChirchikRiverBasin","text":"","code":"ChirchikRiverBasin"},{"path":"/reference/ChirchikRiverBasin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Discharge, precipitation and temperature in the Chirchik river basin,\nUzbekistan. — ChirchikRiverBasin","text":"data frame 29892 rows 14 variables: date Date: Date decadal monthly time steps. data num: Value variable. norm num: Multi-year average values. units chr: Unit values. Can m^3/s (m3s) discharge, mm (mm)                precipitation degrees Celsius (degC) temperature. type Factor: Parameter measured. Can \"Q\" discharge, \"P\"               precipitation \"T\" temperature. code chr: Unique station identifier issued Uzbek HydroMet. station chr: Station name. river chr: Name river station related . basin chr: name basin station part . resolution chr: Temporal resolution data. Can dec data                     10-day intervals (decadal) mon monthly intervals. lon_UTM42 num: Longitude station UTM42. lat_UTM42 num: Latitude station UTM42. altitude_masl num: Altitude station meter mean sea level. basinSize_sqkm num: Size basin square kilometers (km2).","code":""},{"path":"/reference/ChirchikRiverBasin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Discharge, precipitation and temperature in the Chirchik river basin,\nUzbekistan. — ChirchikRiverBasin","text":"Uzbek HydroMet 2021, Andrey Yakovlev","code":""},{"path":"/reference/ErazovsGlacierFunction.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"ErazovsGlacierFunction implements empirical relationship glacier area volume. can used estimate regional glacier volumes Central Asia.","code":""},{"path":"/reference/ErazovsGlacierFunction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"","code":"ErazovsGlacierFunction(glaciers)"},{"path":"/reference/ErazovsGlacierFunction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"glaciers data.frame, tibble, sf object. Must contain attribute \"Area\" kilometers squared (Randolph Glacier Inventory (RGI 6.0)).","code":""},{"path":"/reference/ErazovsGlacierFunction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"Returns input object Volume_Erazov_km3 added. return   NULL length column input object found.","code":""},{"path":"/reference/ErazovsGlacierFunction.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"function deprecated. Please use glacierVolume_Erasov()   instead.","code":""},{"path":"/reference/ErazovsGlacierFunction.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"Erazov, N. V. (1968). Method determining volume mountain glaciers. MGI 14, pp 307-308.","code":""},{"path":[]},{"path":"/reference/ErazovsGlacierFunction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimates glacier surface area and glacier volume. — ErazovsGlacierFunction","text":"","code":"glacier <- dplyr::tibble(Year = c(2000:2010),                          Area = c(0.57, 0.56, 0.55, 0.55, 0.54, 0.53, 0.53,                                   0.52, 0.051, 0.05, 0.048)) ErazovsGlacierFunction(glacier) #> # A tibble: 11 × 3 #>     Year  Area Volume_Erazov_km3 #>    <int> <dbl>             <dbl> #>  1  2000 0.57           0.0116   #>  2  2001 0.56           0.0113   #>  3  2002 0.55           0.0110   #>  4  2003 0.55           0.0110   #>  5  2004 0.54           0.0107   #>  6  2005 0.53           0.0104   #>  7  2006 0.53           0.0104   #>  8  2007 0.52           0.0101   #>  9  2008 0.051          0.000311 #> 10  2009 0.05           0.000302 #> 11  2010 0.048          0.000284"},{"path":"/reference/aggregate_to_monthly.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregates the sub-monthly data in a riversCentralAsia data set to monthly\ndata. — aggregate_to_monthly","title":"Aggregates the sub-monthly data in a riversCentralAsia data set to monthly\ndata. — aggregate_to_monthly","text":"riversCentralAsia data set can type discharge, precipitation, temperature whereby temerature may mean, minimum maximum. function aggregate_data aggregates sub-monthly data data tibble monthly data, according type-function pair given second argument. user specifies aggregation function use data type using timetk's summarise_by_time.","code":""},{"path":"/reference/aggregate_to_monthly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregates the sub-monthly data in a riversCentralAsia data set to monthly\ndata. — aggregate_to_monthly","text":"","code":"aggregate_to_monthly(dataTable, funcTypeLib)"},{"path":"/reference/aggregate_to_monthly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregates the sub-monthly data in a riversCentralAsia data set to monthly\ndata. — aggregate_to_monthly","text":"dataTable tibble format ChirchikRiverBasin. Must contain least columns date, data, norm, type code. funcTypeLib list functions associated data types applied data. Currently, aggregation functions mean sum supported. user specifies data types aggregated either mean sum.","code":""},{"path":"/reference/aggregate_to_monthly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregates the sub-monthly data in a riversCentralAsia data set to monthly\ndata. — aggregate_to_monthly","text":"Returns tibble format data data             aggregated monthly time steps \"mon\" resolution             column.             Returns 1 aggregation fails.","code":""},{"path":[]},{"path":"/reference/aggregate_to_monthly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregates the sub-monthly data in a riversCentralAsia data set to monthly\ndata. — aggregate_to_monthly","text":"","code":"dataTable <- ChirchikRiverBasin funcTypeLib <- list(mean = c(\"Q\", \"T\"), sum= \"P\") data_mon <- aggregate_to_monthly(dataTable, funcTypeLib)"},{"path":"/reference/assess_fc_qual.html","id":null,"dir":"Reference","previous_headings":"","what":"Assesses the quality of decadal or monthly forecasts as done in Central Asian\nHydrometeorological Agencies. — assess_fc_qual","title":"Assesses the quality of decadal or monthly forecasts as done in Central Asian\nHydrometeorological Agencies. — assess_fc_qual","text":"function computes per period (decade month) forecast quality assessment forecast test set provided. Ideally, user provides --sample test set.","code":""},{"path":"/reference/assess_fc_qual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assesses the quality of decadal or monthly forecasts as done in Central Asian\nHydrometeorological Agencies. — assess_fc_qual","text":"","code":"assess_fc_qual(df, plot)"},{"path":"/reference/assess_fc_qual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assesses the quality of decadal or monthly forecasts as done in Central Asian\nHydrometeorological Agencies. — assess_fc_qual","text":"df tibble `date`, `obs`, `pred` `per` column `per` column either decade month specifier (normally given factor). plot TRUE/FALSE plot generated","code":""},{"path":"/reference/assess_fc_qual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assesses the quality of decadal or monthly forecasts as done in Central Asian\nHydrometeorological Agencies. — assess_fc_qual","text":"list tibble per period forecasts acceptable   expressed percentages total test set length average   plus, optionally, handle figure.","code":""},{"path":"/reference/assess_fc_qual.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assesses the quality of decadal or monthly forecasts as done in Central Asian\nHydrometeorological Agencies. — assess_fc_qual","text":"`per` goes 1 12 monthly data 1 36   decadal data.","code":""},{"path":[]},{"path":"/reference/biasCorrect_ERA5_CHELSA.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts ERA5 basin domain from ERA5 raster bricks and scales fields with\nPBCORR CHELSA data so that monthly totals match.\nWrites resulting bias corrected (scaled) data bricks to a (newly) created\nsubdirectory where the raw ERA5 data files are stored. — biasCorrect_ERA5_CHELSA","title":"Extracts ERA5 basin domain from ERA5 raster bricks and scales fields with\nPBCORR CHELSA data so that monthly totals match.\nWrites resulting bias corrected (scaled) data bricks to a (newly) created\nsubdirectory where the raw ERA5 data files are stored. — biasCorrect_ERA5_CHELSA","text":"Extracts ERA5 basin domain ERA5 raster bricks scales fields PBCORR CHELSA data monthly totals match. Writes resulting bias corrected (scaled) data bricks (newly) created subdirectory raw ERA5 data files stored.","code":""},{"path":"/reference/biasCorrect_ERA5_CHELSA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts ERA5 basin domain from ERA5 raster bricks and scales fields with\nPBCORR CHELSA data so that monthly totals match.\nWrites resulting bias corrected (scaled) data bricks to a (newly) created\nsubdirectory where the raw ERA5 data files are stored. — biasCorrect_ERA5_CHELSA","text":"","code":"biasCorrect_ERA5_CHELSA(   dir_ERA5_hourly,   dataType_ERA5,   dir_CHELSA,   startY,   endY,   basinName,   basin_shape_LatLon )"},{"path":"/reference/biasCorrect_ERA5_CHELSA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts ERA5 basin domain from ERA5 raster bricks and scales fields with\nPBCORR CHELSA data so that monthly totals match.\nWrites resulting bias corrected (scaled) data bricks to a (newly) created\nsubdirectory where the raw ERA5 data files are stored. — biasCorrect_ERA5_CHELSA","text":"dir_ERA5_hourly Directory hourly ERA5 data annual NetCDF files stored. dataType_ERA5 Data type, currently 'tp' 't2m' available. dir_CHELSA Directory CHELSA data stored. startY Starting year extraction bias correction (>= 1981) endY Ending year extraction bias correction (<= 2013) basinName Name basin extract, process store data basin_shape_LatLon Basin Shapefile latlon coordinates","code":""},{"path":"/reference/biasCorrect_ERA5_CHELSA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts ERA5 basin domain from ERA5 raster bricks and scales fields with\nPBCORR CHELSA data so that monthly totals match.\nWrites resulting bias corrected (scaled) data bricks to a (newly) created\nsubdirectory where the raw ERA5 data files are stored. — biasCorrect_ERA5_CHELSA","text":"Dateframe dates dd.mm.yyyy hh:mm:ss representation","code":""},{"path":[]},{"path":"/reference/computeAnnualFlowDurationCurve.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","title":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","text":"Computes annual flow duration curve river discharge data set.","code":""},{"path":"/reference/computeAnnualFlowDurationCurve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","text":"","code":"computeAnnualFlowDurationCurve(data, column, date = \"Date\")"},{"path":"/reference/computeAnnualFlowDurationCurve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","text":"data Tibble date discharge columns. column Name column data calculate duration curve . date Name date column","code":""},{"path":"/reference/computeAnnualFlowDurationCurve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","text":"Input tibble sorted data duration stats columns, namely Q: Discharge descending order Ma: day counter 1 365/366 Pa: Exceedance probability percent","code":""},{"path":"/reference/computeAnnualFlowDurationCurve.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","text":"input data tibble grouped, duration stats computed   within group.","code":""},{"path":[]},{"path":"/reference/computeAnnualFlowDurationCurve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the annual flow duration curve of a river discharge data set. — computeAnnualFlowDurationCurve","text":"","code":"# Monthly flow duration curve Qdf <- tibble::tibble(   Date = seq.Date(from = lubridate::as_date(\"2020-01-01\"),                   to = lubridate::as_date(\"2022-12-13\"),                   by = \"month\"),   Q = rep(c(1:6, 6:1), 3) ) DurationCurve <- computeAnnualFlowDurationCurve(Qdf, \"Q\", \"Date\") plot(DurationCurve$Ma, DurationCurve$Q)   # Daily flow duration curve Date = seq.Date(from = lubridate::as_date(\"2019-10-01\"),                 to = lubridate::as_date(\"2040-09-30\"), by = \"day\") Qdfdaily <- tibble::tibble(Date = Date,   Q = sin(2*pi/365*c(1:length(Date))) * stats::runif(length(Date)) +     cos(2*pi/365*c(1:length(Date))) * runif(length(Date)) +     runif(length(Date))*2) DurationCurve <- computeAnnualFlowDurationCurve(Qdfdaily, \"Q\", \"Date\")"},{"path":"/reference/computeDiurnalTemperatureCycle.html","id":null,"dir":"Reference","previous_headings":"","what":"Using ERA5 hourly data, the function computes the diurnal temperature cycle\nfor each station. — computeDiurnalTemperatureCycle","title":"Using ERA5 hourly data, the function computes the diurnal temperature cycle\nfor each station. — computeDiurnalTemperatureCycle","text":"function takes tabular ERA5 input data computes diurnal cycle period interest param$year_min param$yearmax","code":""},{"path":"/reference/computeDiurnalTemperatureCycle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Using ERA5 hourly data, the function computes the diurnal temperature cycle\nfor each station. — computeDiurnalTemperatureCycle","text":"","code":"computeDiurnalTemperatureCycle(era5_data, param)"},{"path":"/reference/computeDiurnalTemperatureCycle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using ERA5 hourly data, the function computes the diurnal temperature cycle\nfor each station. — computeDiurnalTemperatureCycle","text":"era5_data ERA5 csv-file (RS MINERVE Database input) details stations hourly P,T Q data. param Parameter list year_min year_max fields denote period interest mean diurnal per-sttion cycles computed.","code":""},{"path":"/reference/computeDiurnalTemperatureCycle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using ERA5 hourly data, the function computes the diurnal temperature cycle\nfor each station. — computeDiurnalTemperatureCycle","text":"Tibble average diurnal temperature cycles stored column   station.","code":""},{"path":[]},{"path":"/reference/convert2HYY.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts monthly hydro-meteorological time-series data to hydrological year\nvalues. — convert2HYY","title":"Converts monthly hydro-meteorological time-series data to hydrological year\nvalues. — convert2HYY","text":"Conversion hydrological year values Oct. following year end Sept. Cold season warm season components calculated.","code":""},{"path":"/reference/convert2HYY.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts monthly hydro-meteorological time-series data to hydrological year\nvalues. — convert2HYY","text":"","code":"convert2HYY(data2convert, stationCode, typeSel)"},{"path":"/reference/convert2HYY.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts monthly hydro-meteorological time-series data to hydrological year\nvalues. — convert2HYY","text":"data2convert tibble format packaged accompagning dataset ChirchikRiverData stationCode String 5-digit station code typeSel Either 'Q' discharge, 'mean(T)' mean temperatures 'P' total precipitation","code":""},{"path":"/reference/convert2HYY.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts monthly hydro-meteorological time-series data to hydrological year\nvalues. — convert2HYY","text":"tibble dataframe date column hydrological year, cold season   warm season values columns.","code":""},{"path":[]},{"path":"/reference/cutRaster2Basin.html","id":null,"dir":"Reference","previous_headings":"","what":"Cutting raster file to basin shape with reprojection — cutRaster2Basin","title":"Cutting raster file to basin shape with reprojection — cutRaster2Basin","text":"function cuts raster dataset specific basin shapefiles project raster according specified projection.","code":""},{"path":"/reference/cutRaster2Basin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cutting raster file to basin shape with reprojection — cutRaster2Basin","text":"","code":"cutRaster2Basin(rasterIn, aoiRegion_latlon, aoiBasin_UTM, proj_UTM)"},{"path":"/reference/cutRaster2Basin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cutting raster file to basin shape with reprojection — cutRaster2Basin","text":"rasterIn Raster file (e.g. DEM) aoiRegion_latlon Extent object larger region (.e. Central Asia, good choice extent(c(65,80.05,35.95,44.05))). aoiBasin_UTM Extent object basin shapefile proj_UTM CRS UTM projection (.e. 42N Central Asia, use \"+init=epsg:32642\")","code":""},{"path":"/reference/cutRaster2Basin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cutting raster file to basin shape with reprojection — cutRaster2Basin","text":"Projected raster cut basin","code":""},{"path":[]},{"path":"/reference/decadeMaker.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a vector of decadal (10 days) dates — decadeMaker","title":"Creates a vector of decadal (10 days) dates — decadeMaker","text":"function creates decadal 10-days dates vector allows date tagging decadal (10-days) time series. type timeseries usually used hydro-meteorological data former Soviet Republics. intra-months decades can configured dates beginning, middle end decade.","code":""},{"path":"/reference/decadeMaker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a vector of decadal (10 days) dates — decadeMaker","text":"","code":"decadeMaker(s, e, type)"},{"path":"/reference/decadeMaker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a vector of decadal (10 days) dates — decadeMaker","text":"s starting date YYYY-mm-dd format e end date YYYY-mm-dd format type 'start' creates starting decade dates, 'end' creates ending decade dates, 'mid' 'middle creates dates middle decade.","code":""},{"path":"/reference/decadeMaker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a vector of decadal (10 days) dates — decadeMaker","text":"sequence decadal dates","code":""},{"path":[]},{"path":"/reference/doQuantileMapping.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs a quantile mapping bias correction — doQuantileMapping","title":"Performs a quantile mapping bias correction — doQuantileMapping","text":"Bias correction climate model output observations using package qmap Lukas Gudmundsson.","code":""},{"path":"/reference/doQuantileMapping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs a quantile mapping bias correction — doQuantileMapping","text":"","code":"doQuantileMapping(hist_obs, hist_sim, fut_sim)"},{"path":"/reference/doQuantileMapping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs a quantile mapping bias correction — doQuantileMapping","text":"hist_obs Tibble historical observations 1 stations. tibble must contain columns Date (class: Date), Basin (class: chr) Ta Pr (class: num) whereby Ta contains temperatures deg C Pr precipitation mm. hist_sim Tibble simulations historical time series region interest. tibble must contain columns Date (class: Date), Model (class: chr) Ta Pr (class: num) whereby Ta contains temperatures deg C Pr precipitation mm. Model specifies climate model. fut_sim Tibble simulations future climate region interest. tibble must contain columns Date (class: Date), Model (class: chr) climate model, Scenario (class: chr) CC scenario Ta Pr (class: num) whereby Ta contains temperatures deg C Pr precipitation mm.","code":""},{"path":"/reference/doQuantileMapping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs a quantile mapping bias correction — doQuantileMapping","text":"NULL failure.","code":""},{"path":"/reference/doQuantileMapping.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performs a quantile mapping bias correction — doQuantileMapping","text":"assumed observations used bias correction fit   one single tile climate model output.      Temperatures transformed deg K.","code":""},{"path":[]},{"path":"/reference/doQuantileMapping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs a quantile mapping bias correction — doQuantileMapping","text":"","code":"hist_obs <- tibble::tribble(~Date, ~Basin, ~Pr,                             \"1979-01-01\", \"K_eb1\", 0.1,                             \"1979-01-01\", \"K_eb2\", 0.2,                             \"1979-01-01\", \"K_eb3\", 0.3,                             \"1979-01-02\", \"K_eb1\", 0.4,                             \"1979-01-02\", \"K_eb2\", 0.5,                             \"1979-01-02\", \"K_eb3\", 0.6) |>   dplyr::mutate(Date = as.Date(Date)) hist_sim <- hist_obs |>   dplyr::filter(Basin == \"K_eb1\") |>   dplyr::select(-Basin) |>   dplyr::mutate(Pr = Pr + 1, Model = \"A\") hist_sim <- hist_sim |>   dplyr::add_row(hist_sim |>                    dplyr::mutate(Pr = Pr + 2, Model = \"B\")) fut_sim <- hist_sim |>   dplyr::mutate(Scenario = \"a\") |>   dplyr::add_row(hist_sim |>                    dplyr::mutate(Pr = Pr + 1, Scenario = \"b\")) fut_sim <- fut_sim |>   dplyr::add_row(fut_sim |>                    dplyr::mutate(Date = as.Date(Date) + 2))  results <- doQuantileMapping(hist_obs, hist_sim, fut_sim) #> QM hist_sim - Processing model:  A  #> QM hist_sim - Processing model:  B  #> QM fut_sim - Processing Model: A and Scenario a  #> QM fut_sim - Processing Model: A and Scenario b  #> QM fut_sim - Processing Model: B and Scenario a  #> QM fut_sim - Processing Model: B and Scenario b  #> DONE! mapped_hist_sim <- results[[1]] mapped_fut_sim <- results[[2]]"},{"path":"/reference/gen_HRU_Climate_CSV_RSMinerve.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract hydrological response unit HRU specific climate time series from\nnc-files. — gen_HRU_Climate_CSV_RSMinerve","title":"Extract hydrological response unit HRU specific climate time series from\nnc-files. — gen_HRU_Climate_CSV_RSMinerve","text":"Function extracts precipitation (tp) temperature (tas_) data climate raster bricks (observed history obs_hist, GCM-simulated history hist_sim GCM-simulated future (fut_sim) prepares dataframe later import RSMinerve (use readr::write_csv(.,col_names=FALSE)). tp tas_ exported, function called twice resulting tibble columns added.","code":""},{"path":"/reference/gen_HRU_Climate_CSV_RSMinerve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract hydrological response unit HRU specific climate time series from\nnc-files. — gen_HRU_Climate_CSV_RSMinerve","text":"","code":"gen_HRU_Climate_CSV_RSMinerve(   climate_files,   catchmentName,   temp_or_precip,   elBands_shp,   startY,   endY,   obs_frequency,   climate_data_type,   crs_in_use,   output_file_dir = 0,   gcm_model = 0,   gcm_scenario = 0,   tz = \"UTC\" )"},{"path":"/reference/gen_HRU_Climate_CSV_RSMinerve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract hydrological response unit HRU specific climate time series from\nnc-files. — gen_HRU_Climate_CSV_RSMinerve","text":"climate_files List either temperature precipitation climate .nc files process (mix!). Make sure file list time interval consistent startY endY. catchmentName Name catchment data extracted elBands_shp Shapefile hydrological response units. column containing names hydrological response units must name column containing average elevation elevation band must Z. Please make sure shape file UTM coordinates. startY Starting year data made available (assuming data '' available start year) endY Ending year data extracted (assuming data '' actually available end year) obs_frequency Climate observation frequency ('hour', 'day', 'month') climate_data_type String denoting observation type. Either 'hist_obs' (historical observations, .e. CHELSA V21 high resolution climate data), 'hist_sim' (GCM model output data historical period) 'fut_sim' (fture GCM simulations) crs_in_use Proj code crs use. example '+proj=longlat +datum=WGS84' epsg 4326 output_file_dir Path output file dir (empty, file written) tz Time zone information. Default \"UTC\" can overridden. dataType Either 'Temperature' 'Precipitation'","code":""},{"path":"/reference/gen_HRU_Climate_CSV_RSMinerve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract hydrological response unit HRU specific climate time series from\nnc-files. — gen_HRU_Climate_CSV_RSMinerve","text":"Dataframe tibble temperature deg. C. precipitation mm/h","code":""},{"path":"/reference/gen_HRU_Climate_CSV_RSMinerve.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract hydrological response unit HRU specific climate time series from\nnc-files. — gen_HRU_Climate_CSV_RSMinerve","text":"function currently can read input files full years   data, , data January December given year.","code":""},{"path":[]},{"path":"/reference/gen_basinElevationBands.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate basin elevation bands from DEM — gen_basinElevationBands","title":"Generate basin elevation bands from DEM — gen_basinElevationBands","text":"function takes DEM generates altitude bands according interval spacing chosen. also applies different clean operations require user specified values smoothr::drop_crumbs() smoothr::fill_holes() functions. sub-basins, stored shape file can edited QGIS.","code":""},{"path":"/reference/gen_basinElevationBands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate basin elevation bands from DEM — gen_basinElevationBands","text":"","code":"gen_basinElevationBands(   dem_PathN,   dem_FileN = \"DEM.tif\",   demAggFact,   band_interval,   holeSize_km2,   smoothFact,   dem_crs = \"+proj=utm +zone=42 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\" )"},{"path":"/reference/gen_basinElevationBands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate basin elevation bands from DEM — gen_basinElevationBands","text":"dem_PathN Path original stored DEM file. Can path directory containing DEM file path DEM file directly. Can also raster object. dem_FileN DEM file name (optional, defaults DEM.tif) demAggFact Aggregation factor -sample DEM (greatly improves computational efficiency) band_interval Elevation bands interval / spacing (meters) holeSize_km2 Minimum Size holes kept cleaning operation (square kilometers) smoothFact smoothness final elevation bands (smoothness parameter smoothr::smooth() function) dem_crs crs dem proj string. default crs function UTM 42N (EPGS: 32642).","code":""},{"path":"/reference/gen_basinElevationBands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate basin elevation bands from DEM — gen_basinElevationBands","text":"Simple feature (sf) multi-polygon. Returns NULL successful.","code":""},{"path":"/reference/gen_basinElevationBands.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generate basin elevation bands from DEM — gen_basinElevationBands","text":"Note DEM UTM coordinates code works   units projection DEM (example meters UTM   degrees lat/long coordinates). highly recommend work UTM.","code":""},{"path":[]},{"path":"/reference/generateSeqDates.html","id":null,"dir":"Reference","previous_headings":"","what":"POSIXct date sequence generator — generateSeqDates","title":"POSIXct date sequence generator — generateSeqDates","text":"Simple helper function generates simple sequence POSIXct dates specified starting year ending year. frequency can specified. date sequence starts 00:00:00.","code":""},{"path":"/reference/generateSeqDates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"POSIXct date sequence generator — generateSeqDates","text":"","code":"generateSeqDates(startY, endY, freq, tz = \"UTC\")"},{"path":"/reference/generateSeqDates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"POSIXct date sequence generator — generateSeqDates","text":"startY Starting year sequence dates endY Ending year sequence dates freq \"hour\", \"day\", \"week\", \"month\", \"quarter\" \"year\" tz time zone. Default UTC.","code":""},{"path":"/reference/generateSeqDates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"POSIXct date sequence generator — generateSeqDates","text":"Tibble date sequence date frequency specified. date   sequence starts 00:00:00","code":""},{"path":[]},{"path":"/reference/generate_ERA5_Subbasin_CSV.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract subbasin-level and elevation band-specific hourly time series from\nERA5 raster bricks — generate_ERA5_Subbasin_CSV","title":"Extract subbasin-level and elevation band-specific hourly time series from\nERA5 raster bricks — generate_ERA5_Subbasin_CSV","text":"Function extracts precipitation (tp) temperature (t2m) data raster bricks prepares dataframe later import RSMinerve (use write.table() function export csv). tp t2m exported, function called twice resulting tibble columns added.","code":""},{"path":"/reference/generate_ERA5_Subbasin_CSV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract subbasin-level and elevation band-specific hourly time series from\nERA5 raster bricks — generate_ERA5_Subbasin_CSV","text":"","code":"generate_ERA5_Subbasin_CSV(   dir_ERA5_hourly,   catchmentName,   dataType,   elBands_shp,   startY,   endY )"},{"path":"/reference/generate_ERA5_Subbasin_CSV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract subbasin-level and elevation band-specific hourly time series from\nERA5 raster bricks — generate_ERA5_Subbasin_CSV","text":"dir_ERA5_hourly Path original stored DEM file (generate_ERA5_Subbasin_CSV assumes following folder structure: <dir_ERA5_hourly>/<tp t2m>/<catchmentName>/*.nc) catchmentName Name catchment data extracted (depends proper local file storage) dataType Currently, 'tp' 't2m' valid options elBands_shp Subbasin-level shapefile elevation bands startY Starting year data made available (assuming data '' available start year) endY Ending year data extracted (assuming data '' actually available end year)","code":""},{"path":"/reference/generate_ERA5_Subbasin_CSV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract subbasin-level and elevation band-specific hourly time series from\nERA5 raster bricks — generate_ERA5_Subbasin_CSV","text":"Dataframe tibble temperature deg. C. precipitation mm/h","code":""},{"path":[]},{"path":"/reference/getChunkSize.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","title":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","text":"RSMinerve result files can stored .dst files time series model component stored rows. getChunkSize can used determine chunk size model output. Typically used deterimine input readResultDST.","code":""},{"path":"/reference/getChunkSize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","text":"","code":"getChunkSize(start_date, end_date, recordingTimeStep)"},{"path":"/reference/getChunkSize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","text":"start_date Lubridate datetime start simulation end_date Lubridate datetime end simulation recordingTimeStep simulations recording time step (seconds) character numeric.","code":""},{"path":"/reference/getChunkSize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","text":"numeric number time steps, including one header line,   read.","code":""},{"path":"/reference/getChunkSize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","text":"Currently hourly, daily monthly time steps implemented.","code":""},{"path":[]},{"path":"/reference/getChunkSize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the number of time steps to read from DST file for each model\ncomponent. — getChunkSize","text":"","code":"start_date <- lubridate::as_datetime(\"20.01.2021 00:00:00\",                                      format = \"%d.%m.%Y %H:%M:%S\") end_date <- lubridate::as_datetime(\"25.01.2021 00:00:00\",                                    format = \"%d.%m.%Y %H:%M:%S\") recordingTimeStep <- 3600  # In seconds chunk_size <- getChunkSize(start_date, end_date, recordingTimeStep)"},{"path":"/reference/glacierAreaVolume_Aizen.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","title":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","text":"length, surface area volume found Aizen et al. Tien Shan mountains. can used estimate regional glacier volumes.","code":""},{"path":"/reference/glacierAreaVolume_Aizen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","text":"","code":"glacierAreaVolume_Aizen(glaciers)"},{"path":"/reference/glacierAreaVolume_Aizen.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","text":"glaciers data.frame, tibble, sf object. Must contain attribute ```Lmax``` meters (Randolph Glacier Inventory (RGI 6.0)) ```Length [km]``` kilometers ```L(t) [km]``` (output Oerlemans glacier length function).","code":""},{"path":"/reference/glacierAreaVolume_Aizen.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","text":"Returns input object Area_Aizen_km2 Volume_Aizen_km3   added. return NULL length column input object   found.","code":""},{"path":"/reference/glacierAreaVolume_Aizen.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","text":"Aizen, Aizen & Kuzmichonok (2007) Glaciers hydrological   changes Tien Shan: simulation prediction. Environmental Research   Letters. DOI: 10.1088/1748-9326/2/4/045019.","code":""},{"path":[]},{"path":"/reference/glacierAreaVolume_Aizen.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimates glacier surface area and glacier volume. — glacierAreaVolume_Aizen","text":"","code":"glacier <- tibble::tibble(Year = c(2000:2010),                           \"Length [km]\" = c(5.7, 5.6, 5.5, 5.5, 5.4, 5.3,                                             5.3, 5.2, 5.1, 5, 4.8)) glacierAreaVolume_Aizen(glacier) #> # A tibble: 11 × 4 #>     Year `Length [km]` Area_Aizen_km2 Volume_Aizen_km3 #>    <int>         <dbl>          <dbl>            <dbl> #>  1  2000           5.7           8.90            0.606 #>  2  2001           5.6           8.62            0.580 #>  3  2002           5.5           8.35            0.554 #>  4  2003           5.5           8.35            0.554 #>  5  2004           5.4           8.08            0.529 #>  6  2005           5.3           7.82            0.505 #>  7  2006           5.3           7.82            0.505 #>  8  2007           5.2           7.55            0.482 #>  9  2008           5.1           7.30            0.460 #> 10  2009           5             7.04            0.438 #> 11  2010           4.8           6.55            0.396"},{"path":"/reference/glacierArea_Erasov.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates glacier area from glacier volume — glacierArea_Erasov","title":"Calculates glacier area from glacier volume — glacierArea_Erasov","text":"Inverse Erasov glacier scaling function. works positive glacier volume.","code":""},{"path":"/reference/glacierArea_Erasov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates glacier area from glacier volume — glacierArea_Erasov","text":"","code":"glacierArea_Erasov(volume_km3)"},{"path":"/reference/glacierArea_Erasov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates glacier area from glacier volume — glacierArea_Erasov","text":"volume_km3 Glacier volume km3","code":""},{"path":"/reference/glacierArea_Erasov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates glacier area from glacier volume — glacierArea_Erasov","text":"Glacier area km2","code":""},{"path":[]},{"path":"/reference/glacierArea_RGIF.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates glacier area based on glacier volume — glacierArea_RGIF","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"Scaling relationships derived RGI v6.0 region 13 data set, combined glacier thickness derived Farinotti et al. 2019.","code":""},{"path":"/reference/glacierArea_RGIF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"","code":"glacierArea_RGIF(volume_km3)"},{"path":"/reference/glacierArea_RGIF.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"RGI v6.0 <https://www.glims.org/RGI/>,   Farinotti et al., 2019 <https://doi.org/10.1038/s41561-019-0300-3>","code":""},{"path":"/reference/glacierArea_RGIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"volume_km3 glacier volume km3","code":""},{"path":"/reference/glacierArea_RGIF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"glacier area km2","code":""},{"path":"/reference/glacierArea_RGIF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"Assuming normal distribution residuals, relative   uncertainty volume estimate given 2 times standard   deviation relative residuals equal 53   error estimation likely underestimates actual uncertainty.","code":""},{"path":[]},{"path":"/reference/glacierArea_RGIF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates glacier area based on glacier volume — glacierArea_RGIF","text":"","code":"V_km3 <- c(0.1, 1, 10)   A_km2 <- glacierArea_RGIF(V_km3)"},{"path":"/reference/glacierMelt_TI.html","id":null,"dir":"Reference","previous_headings":"","what":"Glacier melt computed with a temperature index model — glacierMelt_TI","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"Glacier melt (M) produced multiplying melt factor   (MF) amount energy available melting   approximated difference measured temperature (T)   threshold temperature melt occurs (Tth).    formula given : M = MF * (T - Tth) T Tth.    melt occurs temperatures threshold temperature.","code":""},{"path":"/reference/glacierMelt_TI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"","code":"glacierMelt_TI(temperature, MF = 4, threshold_temperature = 0)"},{"path":"/reference/glacierMelt_TI.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"Hock R. (2003): Temperature index melt modelling mountain areas.   Journal Hydrology 282, pp 104--115, DOI: 10.1016/S0022-1694(03)00257-9.","code":""},{"path":"/reference/glacierMelt_TI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"temperature matrix daily temperatures time (rows) glacier /elevation band (columns). MF scalar named vector temperature index factors contains one melt factor glacier/elevation band temperature matrix. threshold_temperature scalar named vector temperature glacier melt produced.","code":""},{"path":"/reference/glacierMelt_TI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"matrix melt rates mm per glacier/elevation band.","code":""},{"path":"/reference/glacierMelt_TI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"Hock R., 2003. DOI: 10.1016/S0022-1694(03)00257-9.","code":""},{"path":[]},{"path":"/reference/glacierMelt_TI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Glacier melt computed with a temperature index model — glacierMelt_TI","text":"","code":"# Generate random temperature forcing number_of_glaciers <- 10 number_of_days <- 50*365 temperature <- matrix(   runif(number_of_glaciers * number_of_days, min = -10, max = 10),   nrow = number_of_days, ncol = number_of_glaciers) colnames(temperature) <- paste0(\"Gl\", 1:number_of_glaciers) # Generate sample melt factors MF <- temperature[1, ] * 0 + 1:number_of_glaciers # Calculate glacier melt assuming a threshold temperature for glacier melt of # 1 degree Celcius. melt <- glacierMelt_TI(temperature, MF, threshold_temperature = 1)"},{"path":"/reference/glacierVolume_Erasov.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates glacier volume from glacier area. — glacierVolume_Erasov","title":"Calculates glacier volume from glacier area. — glacierVolume_Erasov","text":"Empirical scaling function calculate glacier volume based glacier area Erasov, 1968. works positive glacier area.","code":""},{"path":"/reference/glacierVolume_Erasov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates glacier volume from glacier area. — glacierVolume_Erasov","text":"","code":"glacierVolume_Erasov(area_km2)"},{"path":"/reference/glacierVolume_Erasov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates glacier volume from glacier area. — glacierVolume_Erasov","text":"area_km2 Glacier area km2","code":""},{"path":"/reference/glacierVolume_Erasov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates glacier volume from glacier area. — glacierVolume_Erasov","text":"Glacier volume km3","code":""},{"path":[]},{"path":"/reference/glacierVolume_RGIF.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","title":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","text":"Scaling relationships derived RGI v6.0 region 13 data set, combined glacier thickness derived Farinotti et al. 2019.","code":""},{"path":"/reference/glacierVolume_RGIF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","text":"","code":"glacierVolume_RGIF(area_km2)"},{"path":"/reference/glacierVolume_RGIF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","text":"area_km2 glacier area km2","code":""},{"path":"/reference/glacierVolume_RGIF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","text":"glacier volume km3","code":""},{"path":"/reference/glacierVolume_RGIF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","text":"Assuming normal distribution residuals, relative   uncertainty volume estimate given 2 times standard   deviation relative residuals equal 31","code":""},{"path":"/reference/glacierVolume_RGIF.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculates glacier volume based on glacier area — glacierVolume_RGIF","text":"derivation empirical relationship well comparison   Erasov function given book [Modelling Hydrological Systems Semi-Arid Central Asia](https://hydrosolutions.github.io/caham_book/glacier_modeling.html).","code":""},{"path":[]},{"path":"/reference/hyear.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the hydrological year for a given date — hyear","title":"Calculates the hydrological year for a given date — hyear","text":"Central Asia hydrological year starts October previous year.","code":""},{"path":"/reference/hyear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the hydrological year for a given date — hyear","text":"","code":"hyear(date)"},{"path":"/reference/hyear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the hydrological year for a given date — hyear","text":"date as_date .POSIXct","code":""},{"path":"/reference/hyear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the hydrological year for a given date — hyear","text":"Hyear numeric","code":""},{"path":[]},{"path":"/reference/hyear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates the hydrological year for a given date — hyear","text":"","code":"Hyear <- hyear(lubridate::as_date(c(\"2015-09-30\", \"2015-10-01\", \"2016-01-27\")))"},{"path":"/reference/loadTabularData.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Tabular Hydro-Meteorological Data — loadTabularData","title":"Load Tabular Hydro-Meteorological Data — loadTabularData","text":"Loads csv files tabular hydrometeorological data years rows decades months columns. function automatically detects monthly decadal (10-day) data provided. function automatically computes long-term norm data provided returns time aware tibble date, data, data norm columns code columns.","code":""},{"path":"/reference/loadTabularData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Tabular Hydro-Meteorological Data — loadTabularData","text":"","code":"loadTabularData(   fPath,   fName,   code,   stationName,   rName,   rBasin,   dataType,   units )"},{"path":"/reference/loadTabularData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load Tabular Hydro-Meteorological Data — loadTabularData","text":"fPath Path input file fName File name (.csv file input required) code Hydrometeorological station code stationName Hydrometeorological station name/location rName Name river rBasin Name basin dataType Type data, either `Q` (discharge data), `T` (temperature data) `P` (precipitation data) units Data units","code":""},{"path":"/reference/loadTabularData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Tabular Hydro-Meteorological Data — loadTabularData","text":"Time-aware tibble relevant data","code":""},{"path":"/reference/loadTabularData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load Tabular Hydro-Meteorological Data — loadTabularData","text":"Note input file needs coma-separated format   without header.  common format hydrological data Central Asia tabular form years rows months decades columns, .e. data 13 columns many rows years data. input file containing monthly data might look like follows:    1990,0.1,0.1,0.2,0.2,0.3,0.3,0.4,0.4,0.3,0.2,0.1,0.1    1991,0.1,0.1,0.2,0.2,0.3,0.3,0.4,0.4,0.3,0.2,0.1,0.1    1992,0.1,0.1,0.2,0.2,0.3,0.3,0.4,0.4,0.3,0.2,0.1,0.1    ...  input file containing decadal data (every 10 days) 37 columns, first year following decade year.","code":""},{"path":[]},{"path":"/reference/loadTabularData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load Tabular Hydro-Meteorological Data — loadTabularData","text":"","code":"if (FALSE) { demo_data <- loadTabularData(   fPath = \"./\",   fName = \"discharge.csv\",   code = \"ABC\",   stationName = \"DemoStation\",   rName = \"Demo River\",   rBasin = \"Demo Basin\",   dataType = \"Q\",   unit = \"m3/s\") }"},{"path":"/reference/load_minerve_input_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","title":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","text":"data csv file can also imported RS Minerve form database.","code":""},{"path":"/reference/load_minerve_input_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","text":"","code":"load_minerve_input_csv(filename)"},{"path":"/reference/load_minerve_input_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","text":"filename Path file input data RS Minerve.","code":""},{"path":"/reference/load_minerve_input_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","text":"Returns tibble format inbuilt data   ChirchikRiverBasin columns date (POSIXct), basin (char),  type (char, T, P Q), unit (char, C, mm/m3/s)  value (num). Data hourly (climate) decadal (10 days)   monthly (discharge) time steps.","code":""},{"path":"/reference/load_minerve_input_csv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","text":"function phased disappear future   package releases. Please refer function readDBCSV instead.","code":""},{"path":[]},{"path":"/reference/load_minerve_input_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reads climate and discharge data into a tibble. — load_minerve_input_csv","text":"","code":"if (FALSE) { load_minerve_input_csv(\"path_to_file.csv\") }"},{"path":"/reference/monDateSeq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a monthly sequence date vector with end of month day dates — monDateSeq","title":"Create a monthly sequence date vector with end of month day dates — monDateSeq","text":"function creates sequence monthly dates start end date. requires specification start end dates frequency. continuous sequence requested, freq 12.","code":""},{"path":"/reference/monDateSeq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a monthly sequence date vector with end of month day dates — monDateSeq","text":"","code":"monDateSeq(st, en, freq)"},{"path":"/reference/monDateSeq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a monthly sequence date vector with end of month day dates — monDateSeq","text":"st start date en end date freq frequence dates (12 continuous monthly dates)","code":""},{"path":"/reference/monDateSeq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a monthly sequence date vector with end of month day dates — monDateSeq","text":"sequence dates","code":""},{"path":[]},{"path":"/reference/parseComparator.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse comparator object — parseComparator","title":"Parse comparator object — parseComparator","text":"Parse comparator object","code":""},{"path":"/reference/parseComparator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse comparator object — parseComparator","text":"","code":"parseComparator(line)"},{"path":"/reference/parseComparator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse comparator object — parseComparator","text":"line line string parsed","code":""},{"path":"/reference/parseComparator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse comparator object — parseComparator","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseGSM.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse GSM object — parseGSM","title":"Parse GSM object — parseGSM","text":"Parse GSM object","code":""},{"path":"/reference/parseGSM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse GSM object — parseGSM","text":"","code":"parseGSM(line)"},{"path":"/reference/parseGSM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse GSM object — parseGSM","text":"line line string parsed","code":""},{"path":"/reference/parseGSM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse GSM object — parseGSM","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseHBV.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse HBV object — parseHBV","title":"Parse HBV object — parseHBV","text":"Parse HBV object","code":""},{"path":"/reference/parseHBV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse HBV object — parseHBV","text":"","code":"parseHBV(line)"},{"path":"/reference/parseHBV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse HBV object — parseHBV","text":"line line string parsed","code":""},{"path":"/reference/parseHBV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse HBV object — parseHBV","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseJunction.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse junction object — parseJunction","title":"Parse junction object — parseJunction","text":"Parse junction object","code":""},{"path":"/reference/parseJunction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse junction object — parseJunction","text":"","code":"parseJunction(line)"},{"path":"/reference/parseJunction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse junction object — parseJunction","text":"line line string parsed","code":""},{"path":"/reference/parseJunction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse junction object — parseJunction","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseKinematic.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse Kinematic object — parseKinematic","title":"Parse Kinematic object — parseKinematic","text":"Parse Kinematic object","code":""},{"path":"/reference/parseKinematic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse Kinematic object — parseKinematic","text":"","code":"parseKinematic(line)"},{"path":"/reference/parseKinematic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse Kinematic object — parseKinematic","text":"line line string parsed","code":""},{"path":"/reference/parseKinematic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse Kinematic object — parseKinematic","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseObject.html","id":null,"dir":"Reference","previous_headings":"","what":"Parses a line with the appropriate function — parseObject","title":"Parses a line with the appropriate function — parseObject","text":"Parses line appropriate function","code":""},{"path":"/reference/parseObject.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parses a line with the appropriate function — parseObject","text":"","code":"parseObject(Object, line)"},{"path":"/reference/parseObject.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parses a line with the appropriate function — parseObject","text":"Object Character string describing object line Character string line read","code":""},{"path":"/reference/parseObject.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parses a line with the appropriate function — parseObject","text":"Tibble containing parameter values read line","code":""},{"path":"/reference/parseSOCONT.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse SOCONT object — parseSOCONT","title":"Parse SOCONT object — parseSOCONT","text":"Parse SOCONT object","code":""},{"path":"/reference/parseSOCONT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse SOCONT object — parseSOCONT","text":"","code":"parseSOCONT(line)"},{"path":"/reference/parseSOCONT.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse SOCONT object — parseSOCONT","text":"line line string parsed","code":""},{"path":"/reference/parseSOCONT.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse SOCONT object — parseSOCONT","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseSource.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse source object — parseSource","title":"Parse source object — parseSource","text":"Parse source object","code":""},{"path":"/reference/parseSource.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse source object — parseSource","text":"","code":"parseSource(line)"},{"path":"/reference/parseSource.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse source object — parseSource","text":"line line string parsed","code":""},{"path":"/reference/parseSource.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse source object — parseSource","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parseStation.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse Station object — parseStation","title":"Parse Station object — parseStation","text":"Parse Station object","code":""},{"path":"/reference/parseStation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse Station object — parseStation","text":"","code":"parseStation(line)"},{"path":"/reference/parseStation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse Station object — parseStation","text":"line line string parsed","code":""},{"path":"/reference/parseStation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse Station object — parseStation","text":"tibble object name, parameter names values","code":""},{"path":"/reference/parse_block.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse individual blocks of data from lines — parse_block","title":"Parse individual blocks of data from lines — parse_block","text":"Internal function called readResultDXT read individual data chunks file.","code":""},{"path":"/reference/parse_block.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse individual blocks of data from lines — parse_block","text":"","code":"parse_block(block_lines, tz = \"UTC\")"},{"path":"/reference/parse_block.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse individual blocks of data from lines — parse_block","text":"block_lines bunch lines read RSMinerve .dst simulation output file. tz Time zone string passed lubridate::as_datetime. Defaults \"UTC\".","code":""},{"path":"/reference/parse_block.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse individual blocks of data from lines — parse_block","text":"tibble data block.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe graphics — %>%","title":"Pipe graphics — %>%","text":"Like dplyr, tidET also uses pipe function, %>% turn function composition series imperative statements.","code":""},{"path":[]},{"path":"/reference/plotAnnualFlowDurationCurve.html","id":null,"dir":"Reference","previous_headings":"","what":"plot the annual flow duration curve of a river discharge data set. — plotAnnualFlowDurationCurve","title":"plot the annual flow duration curve of a river discharge data set. — plotAnnualFlowDurationCurve","text":"plot annual flow duration curve river discharge data set.","code":""},{"path":"/reference/plotAnnualFlowDurationCurve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot the annual flow duration curve of a river discharge data set. — plotAnnualFlowDurationCurve","text":"","code":"plotAnnualFlowDurationCurve(data, column)"},{"path":"/reference/plotAnnualFlowDurationCurve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot the annual flow duration curve of a river discharge data set. — plotAnnualFlowDurationCurve","text":"data tibble output computeAnnualFlowDurationCurve column str name column discharge data plot (computeAnnualFlowDurationCurve()).","code":""},{"path":"/reference/plotAnnualFlowDurationCurve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot the annual flow duration curve of a river discharge data set. — plotAnnualFlowDurationCurve","text":"figure yearly average rating curve (black line)   data individual years grey.","code":""},{"path":[]},{"path":"/reference/plotNormDevHYY.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to plot value deviations from norms for entire hydrological years and\ncold and warm seasons. — plotNormDevHYY","title":"Helper function to plot value deviations from norms for entire hydrological years and\ncold and warm seasons. — plotNormDevHYY","text":"function expects tibble columns 'hyYear' (date), data (dbl), data_cs (dbl) data_ws (dbl) hyYear date column data, data_cs data_ws columns values entire year, cold season (Oct. Mar. Central Asia) warm season (Apr. Sept. Central Asia). following dataType(s) accepted: 'Q' discharge, 'T' temperature deg. C. 'P' precipitation mm/year. data2Plot tibble can easily produced function convert2HYY() part package.","code":""},{"path":"/reference/plotNormDevHYY.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to plot value deviations from norms for entire hydrological years and\ncold and warm seasons. — plotNormDevHYY","text":"","code":"plotNormDevHYY(data2Plot, dataType, stationID)"},{"path":"/reference/plotNormDevHYY.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to plot value deviations from norms for entire hydrological years and\ncold and warm seasons. — plotNormDevHYY","text":"data2Plot tibble dataType String, either 'Q' mean discharge m3/s, 'T' temperature degrees Celsius 'P' precipitation mm/yr. stationID String station name, e.g. 'Khorog-Gunt 17050'","code":""},{"path":"/reference/plotNormDevHYY.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to plot value deviations from norms for entire hydrological years and\ncold and warm seasons. — plotNormDevHYY","text":"ggplot object","code":""},{"path":[]},{"path":"/reference/posixct2rsminerveChar.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to convert POSIXCT-dates to a character representation as required\nby RSminerve — posixct2rsminerveChar","title":"Function to convert POSIXCT-dates to a character representation as required\nby RSminerve — posixct2rsminerveChar","text":"Reformats POSIXct date formats string (vec) format dd.mm.yyyy hh:mm:ss. format RSMinerve accepts time series.","code":""},{"path":"/reference/posixct2rsminerveChar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to convert POSIXCT-dates to a character representation as required\nby RSminerve — posixct2rsminerveChar","text":"","code":"posixct2rsminerveChar(dateVec, tz = \"\")"},{"path":"/reference/posixct2rsminerveChar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to convert POSIXCT-dates to a character representation as required\nby RSminerve — posixct2rsminerveChar","text":"dateVec Date vector tz Optional character indicating time zone .POSIXct. Default system internal time zone (\"\"). \"GTM\" known local time zone data recommended.","code":""},{"path":"/reference/posixct2rsminerveChar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to convert POSIXCT-dates to a character representation as required\nby RSminerve — posixct2rsminerveChar","text":"Dateframe dates dd.mm.yyyy hh:mm:ss representation","code":""},{"path":[]},{"path":"/reference/posixct2rsminerveChar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to convert POSIXCT-dates to a character representation as required\nby RSminerve — posixct2rsminerveChar","text":"","code":"date_vec <- c(\"2018-01-01 01:00:00\", \"2018-01-01 02:00:00\", \"2018-01-01 03:00:00\") rsminerve_date_vec <- posixct2rsminerveChar(date_vec, \"GMT\")"},{"path":"/reference/readDBCSV.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads a RSMinerve data base csv into a tibble. — readDBCSV","title":"Reads a RSMinerve data base csv into a tibble. — readDBCSV","text":"data csv file exported RS Minerve data base tab.","code":""},{"path":"/reference/readDBCSV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads a RSMinerve data base csv into a tibble. — readDBCSV","text":"","code":"readDBCSV(filename, tz = \"UTC\")"},{"path":"/reference/readDBCSV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads a RSMinerve data base csv into a tibble. — readDBCSV","text":"filename Path file db data RS Minerve. tz Optional time zone string, passed lubridate::as_datetime (details refer POSIXt documentation). Defauls \"UTC\"","code":""},{"path":"/reference/readDBCSV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads a RSMinerve data base csv into a tibble. — readDBCSV","text":"Returns tibble format data data         hourly (climate) decadal monthly (discharge) time steps.         Includes attributes csv file","code":""},{"path":"/reference/readDBCSV.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reads a RSMinerve data base csv into a tibble. — readDBCSV","text":"example forcing csv file given http://raw.githubusercontent.com/hydrosolutions/RSMinerveR/main/tests/testthat/test_translateCSVtoDST.csv.   related, older function load_minerve_input_csv   discontinued.","code":""},{"path":[]},{"path":"/reference/readForcingCSV.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads climate and discharge data into a tibble. — readForcingCSV","title":"Reads climate and discharge data into a tibble. — readForcingCSV","text":"data csv file can also imported RS Minerve form database.","code":""},{"path":"/reference/readForcingCSV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads climate and discharge data into a tibble. — readForcingCSV","text":"","code":"readForcingCSV(filename, tz = \"UTC\")"},{"path":"/reference/readForcingCSV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads climate and discharge data into a tibble. — readForcingCSV","text":"filename Path file input data RS Minerve. tz Optional time zone string, passed lubridate::as_datetime (details refer POSIXt documentation). Defauls \"UTC\"","code":""},{"path":"/reference/readForcingCSV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads climate and discharge data into a tibble. — readForcingCSV","text":"Returns tibble format data data         hourly (climate) decadal monthly (discharge) time steps.         Includes attributes csv file","code":""},{"path":"/reference/readForcingCSV.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reads climate and discharge data into a tibble. — readForcingCSV","text":"example forcing csv file given http://raw.githubusercontent.com/hydrosolutions/RSMinerveR/main/tests/testthat/test_translateCSVtoDST.csv","code":""},{"path":[]},{"path":"/reference/readForcingSTR.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads climate and discharge data from a character string into a tibble. — readForcingSTR","title":"Reads climate and discharge data from a character string into a tibble. — readForcingSTR","text":"data string format RSMinerve forcing csv can also imported RS Minerve form database. function useful reformatting data character format written RS Minerve input files.","code":""},{"path":"/reference/readForcingSTR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads climate and discharge data from a character string into a tibble. — readForcingSTR","text":"","code":"readForcingSTR(string, tz = \"UTC\")"},{"path":"/reference/readForcingSTR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads climate and discharge data from a character string into a tibble. — readForcingSTR","text":"string Character string input data RS Minerve. tz Time zone character passed lubridate::as_datetime. Defaults \"UTC\"","code":""},{"path":"/reference/readForcingSTR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads climate and discharge data from a character string into a tibble. — readForcingSTR","text":"Returns tibble format data data         hourly (climate) decadal monthly (discharge) time steps.         Includes attributes csv file.","code":""},{"path":[]},{"path":"/reference/readRSMParameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads parameters from RSMinerve parameter file — readRSMParameters","title":"Reads parameters from RSMinerve parameter file — readRSMParameters","text":"Reads parameters RSMinerve parameter file","code":""},{"path":"/reference/readRSMParameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads parameters from RSMinerve parameter file — readRSMParameters","text":"","code":"readRSMParameters(filepath)"},{"path":"/reference/readRSMParameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads parameters from RSMinerve parameter file — readRSMParameters","text":"filepath Character path file read.","code":""},{"path":"/reference/readRSMParameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads parameters from RSMinerve parameter file — readRSMParameters","text":"Tibble containing parameters read file.","code":""},{"path":"/reference/readRSMParameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reads parameters from RSMinerve parameter file — readRSMParameters","text":"suported RSMInerve objects described vignette   Overview Objects.    `parameters` contains 6 columns:      `Object` (character) identifying RSMinerve object type (e.g.       Station). See Vignette Parameters information objects       available RSMinerveR.      `Name` user specified name object RSMinerve model       (e.g. Meteo station ).      `Zone` name zone object assigned (e.g. \"\").      `Parameters` names parameters object (e.g. X \\[m\\], Y \\[m\\],       etc.). parameter names RS Minerve parameter       file. See Vignette Parameters information parameters       available objects RSMinerveR.      `Values` contains parameter values numerics (e.g. 4500, 3000).","code":""},{"path":[]},{"path":"/reference/readRSMParameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reads parameters from RSMinerve parameter file — readRSMParameters","text":"","code":"if (FALSE) { filepath <- normalizePath(file.path(\"Tutorial_Parameters.txt\")) params <- readRSMParameters(filepath) }"},{"path":"/reference/readResultCSV.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads RS Minerve result file and returns data. — readResultCSV","title":"Reads RS Minerve result file and returns data. — readResultCSV","text":"Reads RS Minerve result file returns data.","code":""},{"path":"/reference/readResultCSV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads RS Minerve result file and returns data. — readResultCSV","text":"","code":"readResultCSV(filename, tz = \"UTC\")"},{"path":"/reference/readResultCSV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads RS Minerve result file and returns data. — readResultCSV","text":"filename Path file read. csv file written saving data Selection plots tab RSMinerve csv file. Depending systems locale, csv may use comas semi-colons separators. decimal separator must point, commas recognized. tz Time zone character passed .POSIXct. Defaults \"UTC\".","code":""},{"path":"/reference/readResultCSV.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads RS Minerve result file and returns data. — readResultCSV","text":"data Tibble data file. Null file found cant read.","code":""},{"path":"/reference/readResultCSV.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reads RS Minerve result file and returns data. — readResultCSV","text":"example RSMinerve results csv file available http://raw.githubusercontent.com/hydrosolutions/RSMinerveR/main/tests/testthat/test_translateCSVtoDST.csv. function generates funny numbers, please check csv file. decimal separators must . ,. find commas please change settings PC (Control Panel, Clock Region, Region, Additional settings, select . Decimal symbol, press \"Apply\" close Control Panel windows. RSMinerve write ,.","code":""},{"path":[]},{"path":"/reference/readResultDST.html","id":null,"dir":"Reference","previous_headings":"","what":"Reading RSMinerve result file — readResultDST","title":"Reading RSMinerve result file — readResultDST","text":"Reading RSMinerve result file","code":""},{"path":"/reference/readResultDST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reading RSMinerve result file — readResultDST","text":"","code":"readResultDST(filepath, chunk_size, tz = \"UTC\")"},{"path":"/reference/readResultDST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reading RSMinerve result file — readResultDST","text":"filepath String path file read. chunk_size Numeric telling many lines read model component. tz Time zone passed as_datetime. Defaults \"UTC\".","code":""},{"path":"/reference/readResultDST.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reading RSMinerve result file — readResultDST","text":"tibble time series simulation results model components.","code":""},{"path":"/reference/readResultDST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reading RSMinerve result file — readResultDST","text":"Use getChunkSize retrieve chunk size simulation resutls read.","code":""},{"path":[]},{"path":"/reference/readResultDST.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reading RSMinerve result file — readResultDST","text":"","code":"if (FALSE) { filepath <- normalizePath(file.path(\"Tutorial01-results.dst\")) chunk_size <- getChunkSize(   lubridate::as_datetime(\"02.09.2013 00:00:00\",format = \"%d.%m.%Y %H:%M:%S\"),   lubridate::as_datetime(\"09.09.2013 00:00:00\", format = \"%d.%m.%Y %H:%M:%S\"),   3600 ) result <- readResultDXT(filepath, chunk_size) }"},{"path":"/reference/readSelectionCHK.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads a chk file containing the variables selected for printing — readSelectionCHK","title":"Reads a chk file containing the variables selected for printing — readSelectionCHK","text":"RSMinerve writes result files performs plots selection variables. selection can stored loaded RSMInerve chk file. function readSelectionCHK reads file tibble.","code":""},{"path":"/reference/readSelectionCHK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads a chk file containing the variables selected for printing — readSelectionCHK","text":"","code":"readSelectionCHK(filepath)"},{"path":"/reference/readSelectionCHK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads a chk file containing the variables selected for printing — readSelectionCHK","text":"filepath Path file read.","code":""},{"path":"/reference/readSelectionCHK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads a chk file containing the variables selected for printing — readSelectionCHK","text":"list name selection content Paths   chk file tibble.","code":""},{"path":"/reference/readSelectionCHK.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reads a chk file containing the variables selected for printing — readSelectionCHK","text":"chk file structured shown following example:     <?xml version=\"1.0\" encoding=\"utf-8\"?>      <Selection>        <Name>New selection<\/Name>       <Path>Model Koksu\\Source QSpring\\Kichkinesay - QUp (m3/s)<\/Path>       <Path>Model Koksu\\Comparator Comparator 1\\QReference (m3/s)<\/Path>       <Path>Model Koksu\\Comparator Comparator 1\\QSimulation (m3/s)<\/Path>       ...     content Path parts parsed tibble columns Model,   Object, ID Variable. output tibble example :       tibble: 94 x 3        Model       Object                     Variable          <chr>       <chr>                      <chr>                   Model Koksu Source QSpring             Kichkinesay - QUp (m3/s)        Model Koksu Comparator Comparator 1    QReference (m3/s)           Model Koksu Comparator Comparator 1    QSimulation (m3/s)          ...         ...                        ...","code":""},{"path":[]},{"path":"/reference/readSelectionCHK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reads a chk file containing the variables selected for printing — readSelectionCHK","text":"","code":"if (FALSE) { filepath <- normalizePath(file.path(\"test_selection.chk\")) selection_list <- readSelectionCHK(filepath) selection_name <- selection_list[[1]] selection_data <- selection_list[[2]] }"},{"path":"/reference/readSpecificLine.html","id":null,"dir":"Reference","previous_headings":"","what":"Read specified line from file — readSpecificLine","title":"Read specified line from file — readSpecificLine","text":"Read specified line file","code":""},{"path":"/reference/readSpecificLine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read specified line from file — readSpecificLine","text":"","code":"readSpecificLine(filepath, linenumber)"},{"path":"/reference/readSpecificLine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read specified line from file — readSpecificLine","text":"filepath Character path file read linenumber numeric list numerics indicating line read","code":""},{"path":"/reference/readSpecificLine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read specified line from file — readSpecificLine","text":"Character line list character lines read file","code":""},{"path":"/reference/translateCSVtoDST.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate csv to dst — translateCSVtoDST","title":"Translate csv to dst — translateCSVtoDST","text":"!DEVELOPMENT! function meant translate forcing data RSMinerve csv format dst can loaded scripting RSMinerve. dst output file written location input file.","code":""},{"path":"/reference/translateCSVtoDST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate csv to dst — translateCSVtoDST","text":"","code":"translateCSVtoDST(csvfilepath, tz = \"UTC\")"},{"path":"/reference/translateCSVtoDST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate csv to dst — translateCSVtoDST","text":"csvfilepath string path csv file read. tz Time zone string passed base::format. Defaults \"UTC\".","code":""},{"path":"/reference/translateCSVtoDST.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Translate csv to dst — translateCSVtoDST","text":"NULL success 1 failure.","code":""},{"path":"/reference/translateCSVtoDST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Translate csv to dst — translateCSVtoDST","text":"scripting RSMinerve, climate forcing read dst files   csv files used RSMinerve run user   interface. csv files can transformed dst files using   function.","code":""},{"path":[]},{"path":"/reference/writeRSMParameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Write parameters to RS Minerve parameter file — writeRSMParameters","title":"Write parameters to RS Minerve parameter file — writeRSMParameters","text":"Write parameters RS Minerve parameter file","code":""},{"path":"/reference/writeRSMParameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write parameters to RS Minerve parameter file — writeRSMParameters","text":"","code":"writeRSMParameters(parameters, outfilepath)"},{"path":"/reference/writeRSMParameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write parameters to RS Minerve parameter file — writeRSMParameters","text":"parameters Tibble parameters RS Minerve object. Multiple parameter sets may possible. See Details & Examples info column requirements. outfilepath Character string path file written.","code":""},{"path":"/reference/writeRSMParameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write parameters to RS Minerve parameter file — writeRSMParameters","text":"NULL success.","code":""},{"path":"/reference/writeRSMParameters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write parameters to RS Minerve parameter file — writeRSMParameters","text":"`parameters` contains 5 columns:    `Object` (character) identifying RSMinerve object type (e.g. Station).     See Vignette Parameters information objects available     RSMinerveR.    `Name` user specified name object RSMinerve model     (e.g. Meteo station ).    `Parameters` names parameters object (e.g. Zone, X \\[m\\],     Y \\[m\\], etc.). See Vignette Parameters information     parameters available objects RSMinerveR.    `Values` contains parameter values (e.g. \"\", 4500, 3000).    `Parameter set` (optional) used differentiate multiple     parameter sets. function write     length(unique(parameters$`Parameter set`)) parameter files, appending     value Parameter set base file name.    outfilepath edited case several parameter sets written","code":""},{"path":[]},{"path":"/reference/writeRSMParameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write parameters to RS Minerve parameter file — writeRSMParameters","text":"","code":"if (FALSE) { filepath <- normalizePath(file.path(\"Tutorial_Parameters.txt\")) params <- readRSMParameters(filepath) params <- params |> mutate(Values = ifelse((Object == \"GSM\" & Parameters == \"Kgl [1/d]\"),                         Values/2, Values)) writeRSMParameters(params, filepath) }"},{"path":"/reference/writeSelectionCHK.html","id":null,"dir":"Reference","previous_headings":"","what":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","title":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","text":"RSMinerve writes result files performs plots selection variables. selection can stored loaded RSMInerve chk file. function writeSelectionCHK writes file tibble.","code":""},{"path":"/reference/writeSelectionCHK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","text":"","code":"writeSelectionCHK(filepath, data, name)"},{"path":"/reference/writeSelectionCHK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","text":"filepath Path file written. data Tibble data frame description variables written. name character string name selection.","code":""},{"path":"/reference/writeSelectionCHK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","text":"NULL successful.","code":""},{"path":"/reference/writeSelectionCHK.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","text":"chk file structured shown following example:     <?xml version=\"1.0\" encoding=\"utf-8\"?>      <Selection>        <Name>New selection<\/Name>       <Path>Model Koksu\\Source QSpring\\Kichkinesay - QUp (m3/s)<\/Path>       <Path>Model Koksu\\Comparator Comparator 1\\QReference (m3/s)<\/Path>       <Path>Model Koksu\\Comparator Comparator 1\\QSimulation (m3/s)<\/Path>       ...     content Path parts parsed tibble columns Model,   Object, ID Variable. input tibble example :       tibble: 94 x 3        Model       Object                     Variable          <chr>       <chr>                      <chr>                   Model Koksu Source QSpring             Kichkinesay - QUp (m3/s)        Model Koksu Comparator Comparator 1    QReference (m3/s)           Model Koksu Comparator Comparator 1    QSimulation (m3/s)          ...         ...                        ...","code":""},{"path":[]},{"path":"/reference/writeSelectionCHK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Writes a chk file containing the variables selected for printing — writeSelectionCHK","text":"","code":"if (FALSE) { filepath <- normalizePath(file.path(\"test_writeSelectionCHK.chk\")) Object_IDs <- c(\"SOCONT 1\", \"SOCONT 2\", \"SOCONT 3\") data <- tibble::tibble(   Model = rep(\"Tutorial_Model\", length(Object_IDs)),   Object = rep(\"SOCONT\", length(Object_IDs)),   ID = Object_IDs,   Variable = rep(\"Qtot (m3/s)\") ) name <- \"SOCONT Qtot\" writeSelectionCHK(filepath, data, name) }"},{"path":"/news/index.html","id":"riverscentralasia-110","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 1.1.0","title":"riversCentralAsia 1.1.0","text":"cleaning package functions documentation - release","code":""},{"path":"/news/index.html","id":"riverscentralasia-041","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.4.1.","title":"riversCentralAsia 0.4.1.","text":"Added import function iEasyHydro .csv files import_iEasyHydro_data()","code":""},{"path":"/news/index.html","id":"riverscentralasia-04","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.4","title":"riversCentralAsia 0.4","text":"numerous additions improvements. following new functions available: computeDiurnalTemperatureCycle() generateHourlyFromDaily_PT()","code":""},{"path":"/news/index.html","id":"riverscentralasia-03","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.3","title":"riversCentralAsia 0.3","text":"several new functions facilitate ) ERA5 data handling, bias correction, donwscaling, etc., b) prepare data stochastic weather generator RMAWGEN c) handle importing exporting files hydrological-hydraulic RS MINERVE model. function biasCorrect_ERA5_CHELSA() function climateScenarioPreparation_RMAWGEN() function downscale_ClimPred_monthly_BasinElBands() function generate_ERA5_Subbasin_CSV() function load_minerve_input_csv function posixct2rsminerveCHar() function prepare_RMAWGEN_input_data()","code":""},{"path":"/news/index.html","id":"riverscentralasia-022","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.2.2","title":"riversCentralAsia 0.2.2","text":"Refined decadeMaker.R accommodate non-full year data ranges","code":""},{"path":"/news/index.html","id":"riverscentralasia-02","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.2","title":"riversCentralAsia 0.2","text":"Release 0.2 include various improvements. pracma package dependencies functions. Removed factors loadTabularData allow loading station data. Added monthly station data precipitation Oygaing station.","code":""},{"path":"/news/index.html","id":"riverscentralasia-013","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.1.3","title":"riversCentralAsia 0.1.3","text":"Now, station code factor. Added gauging station locations corresponding contributing catchment sizes pre-packaged Chirchik river data.","code":""},{"path":"/news/index.html","id":"riverscentralasia-012","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.1.2","title":"riversCentralAsia 0.1.2","text":"Package extension also load meteorological data, including precipitation P temperature T, apart discharge data Q. Fort , function loadTabularData got new argument dataType can take now one following values: {Q,P,T}. Added unit column stores units data loaded char format user can specify, e.g. ‘degC’ temperature degrees Celsius, ‘mm’ cumulative precipitation interval period, .e. 10-days (decadal) monthly, ‘m3s’ average discharge interval period.","code":""},{"path":[]},{"path":"/news/index.html","id":"improvements-0-1-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"riversCentralAsia 0.1.1","text":"Adding optional name river loadTabularData function. Returns additional tibble column corresponding river name. Making sample discharge data available Chirchik River data gauging stations 16279 (Chatkal River, Khudaydod), 16290 (Pskem River, Mullala), 16298 (Nauvalisoy River, Sidzhak) 16294 (Inflow Charvak) included. future, data river basins included.","code":""},{"path":[]},{"path":"/news/index.html","id":"riverscentralasia-010","dir":"Changelog","previous_headings":"","what":"riversCentralAsia 0.1.0","title":"riversCentralAsia 0.1.0","text":"Initial Release","code":""}]
